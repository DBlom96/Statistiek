{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c45f524b-f776-4e3e-9106-1c7188b4b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222fcfa-f39d-4d56-98a2-ed37f9e723bc",
   "metadata": {},
   "source": [
    "# Correlatie en Regressie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "938669e2-7730-4633-b481-24001f17e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(X, Y, labels):\n",
    "    # Start building the LaTeX table\n",
    "    xlabel, ylabel = labels.values()\n",
    "    n = len(X)\n",
    "    alignment_chars = \"{c|\" + \"c\" * n + \"}\"\n",
    "    latex_code = f\"\"\"\n",
    "        \\\\begin{{center}}\n",
    "            \\\\begin{{tabular}}{alignment_chars}\n",
    "                \\\\toprule\n",
    "                    \\\\textbf{{{xlabel}}} {\" \".join([f\"& ${x}$\" for x in X])} \\\\\\\\\n",
    "                    \\\\textbf{{{ylabel}}} {\" \".join([f\"& ${y}$\" for y in Y])} \\\\\\\\\n",
    "                \\\\bottomrule\n",
    "            \\\\end{{tabular}}\n",
    "        \\\\end{{center}}\n",
    "    \"\"\"\n",
    "    \n",
    "    return latex_code\n",
    "\n",
    "def generate_latex_table_regression(X, Y):\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "       \n",
    "    # Start building the LaTeX table\n",
    "    latex_code = \"\"\"\n",
    "        \\\\begin{center}\n",
    "            \\\\begin{tabular}{ccccc}\n",
    "                \\\\toprule\n",
    "                    $x$ & $y$ & $xy$ & $x^2$ & $y^2$ \\\\\\\\\n",
    "                \\\\midrule\n",
    "    \"\"\"\n",
    "    \n",
    "    # Populate table rows\n",
    "    for x, y, xy, x2, y2 in zip(X, Y, X * Y, X ** 2, Y ** 2):\n",
    "        x, y, xy, x2, y2 = map(lambda p: pretty_print(p), (x, y, xy, x2, y2))\n",
    "        latex_code += f\"\\t\\t${x}$ & ${y}$ & ${xy}$ & ${x2}$ & ${y2}$ \\\\\\\\\\n\"\n",
    "    \n",
    "    # Add final row with averages\n",
    "    # Compute averages\n",
    "    avg_X, avg_Y, avg_XY, avg_X2, avg_Y2 = map(lambda x: pretty_print(np.mean(x)), [X, Y, X * Y, X ** 2, Y ** 2])\n",
    "\n",
    "    latex_code += f\"\"\"\n",
    "                \\\\midrule\n",
    "                    $\\\\overline{{x}} = {avg_X}$ & $\\\\overline{{y}} = {avg_Y}$ & $\\\\overline{{xy}} = {avg_XY}$ & $\\\\overline{{x^2}} = {avg_X2}$ & $\\\\overline{{y^2}} = {avg_Y2}$ \\\\\\\\\n",
    "                \\\\bottomrule\n",
    "            \\\\end{{tabular}}\n",
    "        \\\\end{{center}}\n",
    "    \"\"\"    \n",
    "    return latex_code\n",
    "\n",
    "def regression_coefficients_latex(X, Y):  \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    avg_X = np.mean(X)\n",
    "    avg_Y = np.mean(Y)\n",
    "    avg_XY = np.mean(X * Y)\n",
    "    avg_X_squared = np.mean(X ** 2)\n",
    "    \n",
    "    # Beta_1 (slope)\n",
    "    numerator = avg_XY - avg_X * avg_Y\n",
    "    denominator = avg_X_squared - avg_X**2\n",
    "    beta_1 = numerator / denominator\n",
    "    \n",
    "    # Beta_0 (intercept)\n",
    "    beta_0 = avg_Y - beta_1 * avg_X\n",
    "    \n",
    "    # LaTeX output\n",
    "    latex_code = f\"\"\"\n",
    "        \\\\begin{{align*}}\n",
    "            b &= \\\\frac{{\\\\overline{{xy}} - \\\\overline{{x}} \\\\cdot \\\\overline{{y}}}}{{\\\\overline{{x^2}} - (\\\\overline{{x}})^2}} \\\\\\\\\n",
    "              &= \\\\frac{{{pretty_print(avg_XY)} - {pretty_print(avg_X)} \\\\cdot {pretty_print(avg_Y)}}}{{{pretty_print(avg_X_squared)} - ({pretty_print(avg_X)})^2}} \\\\\\\\\n",
    "              &= \\\\frac{{{pretty_print(numerator)}}}{{{pretty_print(denominator)}}} \\\\approx {pretty_print(beta_1)} \\\\\\\\\n",
    "            a &= \\\\overline{{y}} - b \\\\cdot \\\\overline{{x}} \\\\\\\\\n",
    "              &= {pretty_print(avg_Y)} - {pretty_print(beta_1)} \\\\cdot {pretty_print(avg_X)} \\\\\\\\\n",
    "              &\\\\approx {pretty_print(beta_0)}.\n",
    "        \\\\end{{align*}}\n",
    "\n",
    "        De formule van de regressielijn behorende bij deze steekproef is dus gelijk aan $Y = {pretty_print(beta_0)}{beta_1:+.4f}X$.\n",
    "    \"\"\"\n",
    "    return latex_code, beta_0, beta_1\n",
    "\n",
    "\n",
    "def pearson_correlation_latex(X, Y):\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    # Compute necessary statistical values\n",
    "    avg_X, avg_Y, avg_XY, avg_X_squared, avg_Y_squared = np.mean(X), np.mean(Y), np.mean(X*Y), np.mean(X ** 2), np.mean(Y ** 2)\n",
    "\n",
    "    \n",
    "    # Compute Pearson correlation coefficient\n",
    "    numerator = avg_XY - (avg_X * avg_Y)\n",
    "    denominator = np.sqrt((avg_X**2 - avg_X_squared) * (avg_Y**2 - avg_Y_squared))\n",
    "    r = numerator / denominator\n",
    "    \n",
    "    # Generate LaTeX output\n",
    "    latex_code = f\"\"\"\n",
    "        \\\\begin{{align*}}\n",
    "            r(x,y)  &= \\\\frac{{ \\\\overline{{x \\\\cdot y}} - \\\\overline{{x}} \\\\cdot \\\\overline{{y}} }}{{ \\\\sqrt{{ (\\\\overline{{x}}^2 - \\\\overline{{x^2}}) \\\\cdot (\\\\overline{{y}}^2 - \\\\overline{{y^2}}) }} }}\\\\\\\\\n",
    "                    &= \\\\frac{{ {pretty_print(avg_XY)} - {pretty_print(avg_X)} \\\\cdot {pretty_print(avg_Y)} }}{{ \\\\sqrt{{ ({pretty_print(avg_X)}^2 - {pretty_print(avg_X_squared)}) \\\\cdot ({pretty_print(avg_Y)}^{2} - {pretty_print(avg_Y_squared)}) }} }} \\\\\\\\\n",
    "                    &= \\\\frac{{{pretty_print(numerator)}}}{{{pretty_print(denominator)}}} \\\\\\\\\n",
    "                    &\\\\approx {pretty_print(r)}.\n",
    "        \\\\end{{align*}}\n",
    "    \"\"\"\n",
    "    return latex_code\n",
    "\n",
    "def spearman_correlation_latex(X, Y):\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    if len(X) != len(Y):\n",
    "        raise ValueError(\"Beide lijsten moeten dezelfde lengte hebben.\")\n",
    "    \n",
    "    # Rangschik de gegevens\n",
    "    ranks_X, ranks_Y = rankdata(X), rankdata(Y)\n",
    "    print(ranks_X, ranks_Y)\n",
    "    \n",
    "    # Bereken de verschillen in rang\n",
    "    d = ranks_X - ranks_Y\n",
    "    d_squared = d ** 2\n",
    "    sum_d_squared = sum(d_squared)\n",
    "    n = len(X)\n",
    "    alignment_chars = \"c\" + \"c\" * n\n",
    "    \n",
    "    # Spearman's rho\n",
    "    numerator = 6 * np.sum(d_squared)\n",
    "    denominator = n * (n**2 - 1)\n",
    "    rho = 1 - (numerator / denominator)\n",
    "    \n",
    "    # Genereer LaTeX-uitvoer\n",
    "    latex_code = f\"\"\"\n",
    "        De eerste stap bij het berekenen van Spearman's correlatieco\\\\\"effici\\\\\"ent is het bepalen van de rankings van de uitkomsten voor $X$ en $Y$:\n",
    "        \\\\begin{{center}}\n",
    "            \\\\begin{{tabular}}{{{alignment_chars}}}\n",
    "                \\\\toprule\n",
    "                    {{\\\\bfseries Rangnummers $X$-waarden}} {\" \".join([f\"& ${i}$\" for i in ranks_X])} \\\\\\\\\n",
    "                    {{\\\\bfseries Rangnummers $Y$-waarden}} {\" \".join([f\"& ${i}$\" for i in ranks_Y])} \\\\\\\\\n",
    "                \\\\midrule\n",
    "                    {{\\\\bfseries Verschillen $d_i$}} {\" \".join([f\"& ${diff}$\" for diff in d])} \\\\\\\\\n",
    "                    {{\\\\bfseries Kwadratische verschillen $d_i^2$}} {\" \".join([f\"& ${diff2}$\" for diff2 in d_squared])} \\\\\\\\\n",
    "                \\\\bottomrule\n",
    "            \\\\end{{tabular}}\n",
    "        \\\\end{{center}}\n",
    "\n",
    "        De som van de kwadratische rangnummerverschillen is gelijk aan $\\\\sum_i d_i^2 = {sum_d_squared}$.\n",
    "        Aangezien de steekproefgrootte gelijk is aan $n = {n}$, is de rangcorrelatieco\\\\\"effici\\\\\"ent van Spearman gelijk aan\n",
    "        \\\\begin{{align*}}\n",
    "            r_s &= 1 - \\\\frac{{ 6 \\\\cdot \\\\sum_i d_i^2 }}{{ n^3 - n }}  \\\\\\\\\n",
    "                &= 1 - \\\\frac{{ 6 \\\\cdot {sum_d_squared} }}{{ {n}^3 - {n} }}  \\\\\\\\\n",
    "                &\\\\approx {pretty_print(rho)}.\n",
    "        \\\\end{{align*}}\n",
    "    \"\"\"\n",
    "    \n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258f0156-721d-44d1-9c94-9e571b95756d",
   "metadata": {},
   "source": [
    "## Betrouwbaarheidsinterval voor $E[Y]$ en voorspellingsinterval voor $Y$ gegeven $X = x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5299c5f-9583-4110-ad82-9630857900e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_confidence_interval(X, Y, beta_0, beta_1, x0, confidence=0.95):\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    n = len(X)\n",
    "    mean_X = np.mean(X)\n",
    "    mean_Y = np.mean(Y)\n",
    "    mean_X2 = np.mean(X ** 2)\n",
    "    mean_XY = np.mean(X * Y)\n",
    "    mean_Y2 = np.mean(Y ** 2)\n",
    "    confidence_percentage = int(100 * confidence)\n",
    "    \n",
    "    # 1. Compute the error terms and estimate the standard deviation of the error terms\n",
    "    error_terms = Y - (beta_0 + beta_1 * X)\n",
    "    sample_std_error = np.sqrt( np.sum( error_terms ** 2) / (n - 2) ) \n",
    "\n",
    "    # 2. Use the estimate to estimate the standard deviation of the mean Y given x\n",
    "    sample_std_mean = sample_std_error * np.sqrt( 1 / n * (1 + ((x0 - mean_X) ** 2 / (mean_X2 - mean_X ** 2))) )\n",
    "\n",
    "    y_pred = beta_0 + beta_1 * x0   \n",
    "    t_crit = t.ppf((1 + confidence) / 2, df=n - 2)\n",
    "    margin_error = t_crit * sample_std_mean\n",
    "\n",
    "    # Generate LaTeX output\n",
    "    latex_code = f\"\"\"\n",
    "        De eerste stap is om de puntschatting voor $Y$ te bepalen aan de hand van de regressielijn $Y = {pretty_print(beta_0)}{beta_1:+.4f}X$ door $X = {x0}$ in te vullen.\n",
    "        Dit geeft ons een puntschatting van $y_0 = {pretty_print(beta_0)} {beta_1:+.4f} \\\\cdot {x0} \\\\approx {pretty_print(y_pred)}$.\n",
    "        Daarnaast kunnen we de standaardafwijking $\\\\sigma$ van de storingsterm $\\\\varepsilon$ schatten:\n",
    "        \\\\begin{{align*}}\n",
    "            s_{{\\\\varepsilon}} &= \\\\sqrt{{ \\\\frac{{n}}{{n-2}} \\\\cdot \\\\left( \\\\overline{{y^2}} - a \\\\cdot \\\\overline{{y}} - b \\\\cdot \\\\overline{{xy}} \\\\right) }} \\\\\\\\ \n",
    "                               &= \\\\sqrt{{ \\\\frac{{{n}}}{{{n-2}}} \\\\cdot \\\\left( {pretty_print(mean_Y2)} - {pretty_print(beta_0)} \\\\cdot {pretty_print(mean_Y)} - {pretty_print(beta_1)} \\\\cdot {pretty_print(mean_XY)} \\\\right) }} \\\\\\\\ \n",
    "                               &\\\\approx {pretty_print(sample_std_error)}.\n",
    "        \\\\end{{align*}}\n",
    "\n",
    "        Vervolgens kunnen we een puntschatting berekenen van de standaardafwijking van de verwachtingswaarde van $Y$ voor gegeven $X = x_0$:\n",
    "        \\\\begin{{align*}}\n",
    "        s_{{\\\\mu}}  &= s_{{\\\\varepsilon}} \\\\cdot \\\\sqrt{{ \\\\frac{{1}}{{n}} \\\\cdot \\\\left( 1 + \\\\frac{{(x_0 - \\\\overline{{x}})^2}}{{\\\\overline{{x^2}} - \\\\overline{{x}}^2}} \\\\right) }} \\\\\\\\\n",
    "                    &= {sample_std_error} \\\\cdot \\\\sqrt{{ \\\\frac{{1}}{{{n}}} \\\\cdot \\\\left( 1 + \\\\frac{{({pretty_print(x0)} - {pretty_print(mean_X)})^2}}{{{pretty_print(mean_X2)} - {pretty_print(mean_X)}^2}} \\\\right) }} \\\\\\\\\n",
    "                    &\\\\approx {pretty_print(sample_std_mean)}.   \n",
    "        \\\\end{{align*}}\n",
    "\n",
    "        Omdat we de standaardafwijkingen geschat hebben en de storingstermen normaal verdeeld zijn, moeten we werken met de $t$-verdeling met $df = n - 2 = {n-2}$ vrijheidsgraden.\n",
    "        De $t$-waarde die hoort bij een betrouwbaarheidsniveau $\\\\alpha = {1-confidence}$ is gelijk aan\n",
    "        \\\\[\n",
    "            t = \\\\invt(\\\\text{{opp}} = 1 - \\\\alpha / 2; \\\\text{{df}} = n - 2) = \\\\invt(\\\\text{{opp}} = {1-alpha/2}; \\\\text{{df}} = {n-2}) \\\\approx {pretty_print(t_crit)}.\n",
    "        \\\\]\n",
    "        Het ${int(100 * confidence)}\\\\%$-betrouwbaarheidsinterval voor de gemiddelde $Y$ voor gegeven $X = x_0$ kan dus worden beschreven door\n",
    "        \\\\begin{{align*}}\n",
    "            &[y_0 - t \\\\cdot s_{{\\\\mu}}; y_0 - t \\\\cdot s_{{\\\\mu}}] \\\\\\\\\n",
    "            &= [{pretty_print(y_pred)} - {pretty_print(t_crit)} \\\\cdot {pretty_print(sample_std_mean)}; {pretty_print(y_pred)} + {pretty_print(t_crit)} \\\\cdot {pretty_print(sample_std_mean)}] \\\\\\\\\n",
    "            &\\\\approx [{pretty_print(y_pred - margin_error)}; {pretty_print(y_pred + margin_error)}].\n",
    "        \\\\end{{align*}}\n",
    "        \n",
    "        Met \\\\SI{{{confidence_percentage}}}{{\\\\percent}} betrouwbaarheid ligt het gemiddelde van $Y$ voor gegeven $X = {x0}$ tussen ${pretty_print(y_pred - margin_error)}$ en ${pretty_print(y_pred + margin_error)}$.       \n",
    "    \"\"\"\n",
    "    ci = (y_pred - margin_error, y_pred + margin_error)\n",
    "    return latex_code, y_pred, ci\n",
    "\n",
    "def regression_prediction_interval(X, Y, beta_0, beta_1, x0, confidence=0.95):\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    n = len(X)\n",
    "    mean_X = np.mean(X)\n",
    "    mean_Y = np.mean(Y)\n",
    "    mean_X2 = np.mean(X ** 2)\n",
    "    mean_XY = np.mean(X * Y)\n",
    "    mean_Y2 = np.mean(Y ** 2)\n",
    "    confidence_percentage = int(100 * confidence)\n",
    "\n",
    "    error_terms = Y - (beta_0 + beta_1 * X)\n",
    "    sample_std_error = np.sqrt( np.sum(error_terms ** 2) / (n - 2) )\n",
    "\n",
    "    sample_std_pred = sample_std_error * np.sqrt( 1 + 1 / n * (1 + ((x0 - mean_X) ** 2 / (mean_X2 - mean_X ** 2))) )\n",
    "\n",
    "    y_pred = beta_0 + beta_1 * x0\n",
    "    t_crit = t.ppf((1 + confidence) / 2, df=n - 2)\n",
    "    margin_error = t_crit * sample_std_pred\n",
    "    pi_left, pi_right = (y_pred - margin_error, y_pred + margin_error)\n",
    "    latex_code = f\"\"\"\n",
    "        De eerste stap is om de puntschatting voor $Y$ te bepalen aan de hand van de regressielijn $Y = {pretty_print(beta_0)}{beta_1:+.4f} \\\\cdot X$ door $X = {x0}$ in te vullen.\n",
    "        Dit geeft ons een puntschatting van $y_0 = {pretty_print(beta_0)} {beta_1:+.4f} \\\\cdot {x0} \\\\approx {pretty_print(y_pred)}$.\n",
    "        Daarnaast kunnen we de standaardafwijking $\\\\sigma$ van de storingsterm $\\\\varepsilon$ schatten:\n",
    "        \\\\begin{{align*}}\n",
    "            s_{{\\\\varepsilon}} &= \\\\sqrt{{ \\\\frac{{n}}{{n-2}} \\\\cdot \\\\left( \\\\overline{{y^2}} - a \\\\cdot \\\\overline{{y}} - b \\\\cdot \\\\overline{{xy}} \\\\right) }} \\\\\\\\ \n",
    "                               &= \\\\sqrt{{ \\\\frac{{{n}}}{{{n-2}}} \\\\cdot \\\\left( {pretty_print(mean_Y2)} - {pretty_print(beta_0)} \\\\cdot {pretty_print(mean_Y)} - {pretty_print(beta_1)} \\\\cdot {pretty_print(mean_XY)} \\\\right) }} \\\\\\\\ \n",
    "                               &\\\\approx {pretty_print(sample_std_error)}. \n",
    "        \\\\end{{align*}}\n",
    "\n",
    "        Vervolgens kunnen we een puntschatting berekenen van de standaardafwijking van $Y$ voor gegeven $X = x_0$:\n",
    "        \\\\begin{{align*}}\n",
    "            s_{{f}} &= s_{{\\\\varepsilon}} \\\\cdot \\\\sqrt{{ 1 + \\\\frac{{1}}{{n}} \\\\cdot \\\\left( 1 + \\\\frac{{(x_0 - \\\\overline{{x}})^2}}{{\\\\overline{{x^2}} - \\\\overline{{x}}^2}} \\\\right) }} \\\\\\\\\n",
    "                    &= {pretty_print(sample_std_error)} \\\\cdot \\\\sqrt{{ 1 + \\\\frac{{1}}{{{n}}} \\\\cdot \\\\left( 1 + \\\\frac{{({x0} - {pretty_print(mean_X)})^2}}{{{pretty_print(mean_X2)} - {pretty_print(mean_X)}^2}} \\\\right) }} \\\\\\\\\n",
    "                    &\\\\approx {pretty_print(sample_std_pred)}.         \n",
    "        \\\\end{{align*}}\n",
    "\n",
    "        Omdat we de standaardafwijkingen geschat hebben en de storingstermen normaal verdeeld zijn, moeten we werken met de $t$-verdeling met $df = n - 2 = {n-2}$ vrijheidsgraden.\n",
    "        De $t$-waarde die hoort bij een betrouwbaarheidsniveau $\\\\alpha = {1-confidence}$ is gelijk aan\n",
    "        \\\\[\n",
    "            t = \\\\invt(\\\\text{{opp}} = 1 - \\\\alpha / 2; \\\\text{{df}} = n - 2) = \\\\invt(\\\\text{{opp}} = {1-alpha/2}; \\\\text{{df}} = {n-2}) \\\\approx {pretty_print(t_crit)}.\n",
    "        \\\\]\n",
    "        Het \\\\SI{{{confidence_percentage}}}{{\\\\percent}}-betrouwbaarheidsinterval voor de gemiddelde $Y$ voor gegeven $X = x_0$ kan dus worden beschreven door\n",
    "        \\\\begin{{align*}}\n",
    "            &[y_0 - t \\\\cdot s_{{f}}; y_0 - t \\\\cdot s_{{f}}] \\\\\\\\ \n",
    "            &= [{pretty_print(y_pred)} - {pretty_print(t_crit)} \\\\cdot {pretty_print(sample_std_pred)}; {pretty_print(y_pred)} + {pretty_print(t_crit)} \\\\cdot {pretty_print(sample_std_pred)}] \\\\\\\\ \n",
    "            &\\\\approx [{pretty_print(y_pred - margin_error)}; {pretty_print(y_pred + margin_error)}]. \n",
    "        \\\\end{{align*}}\n",
    "        \n",
    "        Met \\\\SI{{{confidence_percentage}}}{{\\\\percent}} betrouwbaarheid ligt een toekomstige uitkomst van $Y$ voor gegeven $X = {x0}$ tussen ${pretty_print(pi_left)}$ en ${pretty_print(pi_right)}$.\n",
    "    \"\"\"\n",
    "\n",
    "    return latex_code, y_pred, (pi_left, pi_right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af920de3-f8f9-4b77-a4bb-4cc2b048df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_midpoint_lines_and_quadrants(mean_X, mean_Y):\n",
    "    left, right = plt.xlim()\n",
    "    bottom, top = plt.ylim()\n",
    "\n",
    "    plt.axvline(mean_X, linestyle=\"--\", color=secondary_plot_color)\n",
    "    plt.axhline(mean_Y, linestyle=\"--\", color=secondary_plot_color)\n",
    "\n",
    "    p, q = 0.2, 0.8\n",
    "    quadrant_labels = [\n",
    "        (p * mean_X + (1 - p) * right, q * mean_Y + (1 - q) * top, \"> 0\", \"> 0\"),\n",
    "        (p * mean_X + (1 - p) * left, q * mean_Y + (1 - q) * top, \"< 0\", \"> 0\"),\n",
    "        (p * mean_X + (1 - p) * left, q * mean_Y + (1 - q) * bottom, \"< 0\", \"< 0\"),\n",
    "        (p * mean_X + (1 - p) * right, q * mean_Y + (1 - q) * bottom, \"> 0\", \"< 0\"),\n",
    "    ]\n",
    "    for x, y, dx, dy in quadrant_labels:\n",
    "        plt.text(x, y, f\"$x_i - \\\\overline{{x}} {dx}$\\n$y_i - \\\\overline{{y}} {dy}$\", ha=\"center\", va=\"center\")\n",
    "\n",
    "def fit_regression_and_plot_line(X, Y):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, Y)\n",
    "    x_vals = np.linspace(np.min(X), np.max(X), 200).reshape(-1, 1)\n",
    "    y_hat = model.predict(x_vals)\n",
    "\n",
    "    m, b = model.coef_[0], model.intercept_\n",
    "    label = f\"Regressielijn: $Y = {pretty_print(b)}{m:+.4f}X$\"\n",
    "    plt.plot(x_vals, y_hat, color=critical_color, label=label)\n",
    "\n",
    "    return model, x_vals.ravel(), y_hat\n",
    "\n",
    "def plot_residuals(X, Y, model):\n",
    "    for i, (xi, yi) in enumerate(zip(X[:, 0], Y)):\n",
    "        y_pred = model.predict([[xi]])[0]\n",
    "        label = \"Afstanden: $e_i = y_i - (a + b \\\\cdot x_i)$\" if i == 0 else None\n",
    "        plt.plot([xi, xi], [yi, y_pred], linestyle=\"--\", color=primary_plot_color, alpha=0.6, label=label)\n",
    "    \n",
    "def plot_y0(x_0, model):\n",
    "    left, right = plt.xlim()\n",
    "    bottom, top = plt.ylim()\n",
    "    y_0 = model.predict([[x_0]])[0]\n",
    "\n",
    "    plt.plot([x_0, x_0], [bottom, y_0], linestyle=\"--\", color=primary_plot_color)\n",
    "    plt.plot([left, x_0], [y_0, y_0], linestyle=\"--\", color=primary_plot_color,\n",
    "             label=f\"Puntschatting voor $Y \\\\mid X = {x_0}$: ${pretty_print(y_0)}$\")\n",
    "\n",
    "def plot_intervals(X, Y, x_vals, y_hat, model, x_0, plot_prediction_interval, plot_confidence_interval):\n",
    "    n = len(X)\n",
    "    x_mean = np.mean(X)\n",
    "    Sxx = np.sum((X - x_mean) ** 2)\n",
    "    residuals = Y - model.predict(X)\n",
    "    s_squared = np.sum(residuals ** 2) / (n - 2)\n",
    "    s = np.sqrt(s_squared)\n",
    "    t_val = t.ppf(0.975, df=n - 2)\n",
    "\n",
    "    se_mean = s * np.sqrt(1/n + (x_vals - x_mean)**2 / Sxx)\n",
    "    se_pred = s * np.sqrt(1 + 1/n + (x_vals - x_mean)**2 / Sxx)\n",
    "\n",
    "    ci_upper, ci_lower = y_hat + t_val * se_mean, y_hat - t_val * se_mean\n",
    "    pi_upper, pi_lower = y_hat + t_val * se_pred, y_hat - t_val * se_pred\n",
    "\n",
    "    if plot_prediction_interval:\n",
    "        plt.fill_between(x_vals, pi_lower, pi_upper, color=critical_color, alpha=0.2,\n",
    "                         label='Voorspellingsinterval (voor $Y \\\\mid X$)')\n",
    "        if x_0:\n",
    "            y_0 = model.predict([[x_0]])[0]\n",
    "            se_pred_0 = s * np.sqrt(1 + 1/n + (x_0 - x_mean)**2 / Sxx)\n",
    "            lower, upper = y_0 - t_val * se_pred_0, y_0 + t_val * se_pred_0\n",
    "            plt.plot([x_0, x_0], [lower, upper], color=critical_color, linestyle=\"--\", alpha=0.3,\n",
    "                     label=f'Voorspellingsinterval (voor $Y \\\\mid X={x_0}$): [{pretty_print(lower)}; {pretty_print(upper)}]')\n",
    "\n",
    "    if plot_confidence_interval:\n",
    "        plt.fill_between(x_vals, ci_lower, ci_upper, color=acceptable_color, alpha=0.3,\n",
    "                         label='Betrouwbaarheidsinterval (voor $E[Y \\\\mid X]$)')\n",
    "        if x_0:\n",
    "            y_0 = model.predict([[x_0]])[0]\n",
    "            se_mean_0 = s * np.sqrt(1/n + (x_0 - x_mean)**2 / Sxx)\n",
    "            lower, upper = y_0 - t_val * se_mean_0, y_0 + t_val * se_mean_0\n",
    "            plt.plot([x_0, x_0], [lower, upper], color=acceptable_color, linestyle=\"--\", alpha=0.3,\n",
    "                     label=f'Betrouwbaarheidsinterval (voor $E[Y \\\\mid X={x_0}$): [{pretty_print(lower)}; {pretty_print(upper)}]')\n",
    "            \n",
    "\n",
    "def plot_linear_regression(\n",
    "        X, Y, labels, filename, x_0=None,\n",
    "        plot_midpoint_lines=False, plot_least_squares=False, plot_regression_line=False, \n",
    "        plot_point_estimate=False,\n",
    "        plot_prediction_interval=False, plot_confidence_interval=False\n",
    "):\n",
    "    # Convert lists to numpy arrays\n",
    "    X = np.array(X).reshape(-1, 1)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    mean_X, mean_Y = np.mean(X), np.mean(Y)\n",
    "\n",
    "    # Create scatter plot\n",
    "    plt.scatter(X, Y, color=primary_plot_color)\n",
    "    plt.title(f'Spreidingsdiagram: {labels[\"X\"]} vs. {labels[\"Y\"]}')\n",
    "    \n",
    "    # Label axes and add title\n",
    "    plt.xlabel(labels[\"X\"])\n",
    "    plt.ylabel(labels[\"Y\"])\n",
    "\n",
    "    if plot_midpoint_lines:\n",
    "        add_midpoint_lines_and_quadrants(mean_X, mean_Y)\n",
    "              \n",
    "    if plot_regression_line:\n",
    "        model, x_vals, y_hat = fit_regression_and_plot_line(X, Y)\n",
    "    \n",
    "        if plot_least_squares:\n",
    "            plot_residuals(X, Y, model)\n",
    "\n",
    "        if x_0 and plot_point_estimate:\n",
    "            plot_y0(x_0, model)\n",
    "    \n",
    "        if plot_prediction_interval or plot_confidence_interval:\n",
    "            plot_intervals(X, Y, x_vals, y_hat, model, x_0, plot_prediction_interval, plot_confidence_interval)\n",
    "\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=1)\n",
    "\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(filename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e916c7db-d9a9-4f84-a638-8c51bcd3789c",
   "metadata": {},
   "source": [
    "### Voorbeeld gebruik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a992cc1a-e5a4-46fd-8c1a-ef4ad689dcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        \\begin{center}\n",
      "            \\begin{tabular}{c|ccccccccc}\n",
      "                \\toprule\n",
      "                    \\textbf{Slaaptijd (in uren)} & $80$ & $81$ & $80$ & $70$ & $72$ & $69$ & $65$ & $74$ & $80$ \\\\\n",
      "                    \\textbf{Hersteltijd na zware inspanning (in uren)} & $80$ & $74$ & $73$ & $72$ & $78$ & $75$ & $70$ & $74$ & $69$ \\\\\n",
      "                \\bottomrule\n",
      "            \\end{tabular}\n",
      "        \\end{center}\n",
      "    \n",
      "\n",
      "        \\begin{center}\n",
      "            \\begin{tabular}{ccccc}\n",
      "                \\toprule\n",
      "                    $x$ & $y$ & $xy$ & $x^2$ & $y^2$ \\\\\n",
      "                \\midrule\n",
      "    \t\t$80$ & $80$ & $6400$ & $6400$ & $6400$ \\\\\n",
      "\t\t$81$ & $74$ & $5994$ & $6561$ & $5476$ \\\\\n",
      "\t\t$80$ & $73$ & $5840$ & $6400$ & $5329$ \\\\\n",
      "\t\t$70$ & $72$ & $5040$ & $4900$ & $5184$ \\\\\n",
      "\t\t$72$ & $78$ & $5616$ & $5184$ & $6084$ \\\\\n",
      "\t\t$69$ & $75$ & $5175$ & $4761$ & $5625$ \\\\\n",
      "\t\t$65$ & $70$ & $4550$ & $4225$ & $4900$ \\\\\n",
      "\t\t$74$ & $74$ & $5476$ & $5476$ & $5476$ \\\\\n",
      "\t\t$80$ & $69$ & $5520$ & $6400$ & $4761$ \\\\\n",
      "\n",
      "                \\midrule\n",
      "                    $\\overline{x} = 74.5556$ & $\\overline{y} = 73.8889$ & $\\overline{xy} = 5512.3333$ & $\\overline{x^2} = 5589.6667$ & $\\overline{y^2} = 5470.5556$ \\\\\n",
      "                \\bottomrule\n",
      "            \\end{tabular}\n",
      "        \\end{center}\n",
      "    \n",
      "\n",
      "        \\begin{align*}\n",
      "            b &= \\frac{\\overline{xy} - \\overline{x} \\cdot \\overline{y}}{\\overline{x^2} - (\\overline{x})^2} \\\\\n",
      "              &= \\frac{5512.3333 - 74.5556 \\cdot 73.8889}{5589.6667 - (74.5556)^2} \\\\\n",
      "              &= \\frac{3.5062}{31.1358} \\approx 0.1126 \\\\\n",
      "            a &= \\overline{y} - b \\cdot \\overline{x} \\\\\n",
      "              &= 73.8889 - 0.1126 \\cdot 74.5556 \\\\\n",
      "              &\\approx 65.4933.\n",
      "        \\end{align*}\n",
      "\n",
      "        De formule van de regressielijn behorende bij deze steekproef is dus gelijk aan $Y = 65.4933+0.1126X$.\n",
      "    \n",
      "Voorspelde waarde voor $Y$ bij $X = 6.75$ is gelijk aan 66.25337034100016\n",
      "\n",
      "        \\begin{align*}\n",
      "            r(x,y)  &= \\frac{ \\overline{x \\cdot y} - \\overline{x} \\cdot \\overline{y} }{ \\sqrt{ (\\overline{x}^2 - \\overline{x^2}) \\cdot (\\overline{y}^2 - \\overline{y^2}) } }\\\\\n",
      "                    &= \\frac{ 5512.3333 - 74.5556 \\cdot 73.8889 }{ \\sqrt{ (74.5556^2 - 5589.6667) \\cdot (73.8889^2 - 5470.5556) } } \\\\\n",
      "                    &= \\frac{3.5062}{18.4962} \\\\\n",
      "                    &\\approx 0.1896.\n",
      "        \\end{align*}\n",
      "    \n",
      "[7. 9. 7. 3. 4. 2. 1. 5. 7.] [9.  5.5 4.  3.  8.  7.  2.  5.5 1. ]\n",
      "\n",
      "        De eerste stap bij het berekenen van Spearman's correlatieco\\\"effici\\\"ent is het bepalen van de rankings van de uitkomsten voor $X$ en $Y$:\n",
      "        \\begin{center}\n",
      "            \\begin{tabular}{cccccccccc}\n",
      "                \\toprule\n",
      "                    {\\bfseries Rangnummers $X$-waarden} & $7.0$ & $9.0$ & $7.0$ & $3.0$ & $4.0$ & $2.0$ & $1.0$ & $5.0$ & $7.0$ \\\\\n",
      "                    {\\bfseries Rangnummers $Y$-waarden} & $9.0$ & $5.5$ & $4.0$ & $3.0$ & $8.0$ & $7.0$ & $2.0$ & $5.5$ & $1.0$ \\\\\n",
      "                \\midrule\n",
      "                    {\\bfseries Verschillen $d_i$} & $-2.0$ & $3.5$ & $3.0$ & $0.0$ & $-4.0$ & $-5.0$ & $-1.0$ & $-0.5$ & $6.0$ \\\\\n",
      "                    {\\bfseries Kwadratische verschillen $d_i^2$} & $4.0$ & $12.25$ & $9.0$ & $0.0$ & $16.0$ & $25.0$ & $1.0$ & $0.25$ & $36.0$ \\\\\n",
      "                \\bottomrule\n",
      "            \\end{tabular}\n",
      "        \\end{center}\n",
      "\n",
      "        De som van de kwadratische rangnummerverschillen is gelijk aan $\\sum_i d_i^2 = 103.5$.\n",
      "        Aangezien de steekproefgrootte gelijk is aan $n = 9$, is de rangcorrelatieco\\\"effici\\\"ent van Spearman gelijk aan\n",
      "        \\begin{align*}\n",
      "            r_s &= 1 - \\frac{ 6 \\cdot \\sum_i d_i^2 }{ n^3 - n }  \\\\\n",
      "                &= 1 - \\frac{ 6 \\cdot 103.5 }{ 9^3 - 9 }  \\\\\n",
      "                &\\approx 0.1375.\n",
      "        \\end{align*}\n",
      "    \n",
      "\n",
      "        De eerste stap is om de puntschatting voor $Y$ te bepalen aan de hand van de regressielijn $Y = 65.4933+0.1126X$ door $X = 6.75$ in te vullen.\n",
      "        Dit geeft ons een puntschatting van $y_0 = 65.4933 +0.1126 \\cdot 6.75 \\approx 66.2534$.\n",
      "        Daarnaast kunnen we de standaardafwijking $\\sigma$ van de storingsterm $\\varepsilon$ schatten:\n",
      "        \\begin{align*}\n",
      "            s_{\\varepsilon} &= \\sqrt{ \\frac{n}{n-2} \\cdot \\left( \\overline{y^2} - a \\cdot \\overline{y} - b \\cdot \\overline{xy} \\right) } \\\\ \n",
      "                               &= \\sqrt{ \\frac{9}{7} \\cdot \\left( 5470.5556 - 65.4933 \\cdot 73.8889 - 0.1126 \\cdot 5512.3333 \\right) } \\\\ \n",
      "                               &\\approx 3.6904.\n",
      "        \\end{align*}\n",
      "\n",
      "        Vervolgens kunnen we een puntschatting berekenen van de standaardafwijking van de verwachtingswaarde van $Y$ voor gegeven $X = x_0$:\n",
      "        \\begin{align*}\n",
      "        s_{\\mu}  &= s_{\\varepsilon} \\cdot \\sqrt{ \\frac{1}{n} \\cdot \\left( 1 + \\frac{(x_0 - \\overline{x})^2}{\\overline{x^2} - \\overline{x}^2} \\right) } \\\\\n",
      "                    &= 3.690440315523678 \\cdot \\sqrt{ \\frac{1}{9} \\cdot \\left( 1 + \\frac{(6.75 - 74.5556)^2}{5589.6667 - 74.5556^2} \\right) } \\\\\n",
      "                    &\\approx 14.9988.   \n",
      "        \\end{align*}\n",
      "\n",
      "        Omdat we de standaardafwijkingen geschat hebben en de storingstermen normaal verdeeld zijn, moeten we werken met de $t$-verdeling met $df = n - 2 = 7$ vrijheidsgraden.\n",
      "        De $t$-waarde die hoort bij een betrouwbaarheidsniveau $\\alpha = 0.09999999999999998$ is gelijk aan\n",
      "        \\[\n",
      "            t = \\invt(\\text{opp} = 1 - \\alpha / 2; \\text{df} = n - 2) = \\invt(\\text{opp} = 0.95; \\text{df} = 7) \\approx 1.8946.\n",
      "        \\]\n",
      "        Het $90\\%$-betrouwbaarheidsinterval voor de gemiddelde $Y$ voor gegeven $X = x_0$ kan dus worden beschreven door\n",
      "        \\begin{align*}\n",
      "            &[y_0 - t \\cdot s_{\\mu}; y_0 - t \\cdot s_{\\mu}] \\\\\n",
      "            &= [66.2534 - 1.8946 \\cdot 14.9988; 66.2534 + 1.8946 \\cdot 14.9988] \\\\\n",
      "            &\\approx [37.8369; 94.6699].\n",
      "        \\end{align*}\n",
      "        \n",
      "        Met \\SI{90}{\\percent} betrouwbaarheid ligt het gemiddelde van $Y$ voor gegeven $X = 6.75$ tussen $37.8369$ en $94.6699$.       \n",
      "    \n",
      "\n",
      "        De eerste stap is om de puntschatting voor $Y$ te bepalen aan de hand van de regressielijn $Y = 65.4933+0.1126 \\cdot X$ door $X = 6.75$ in te vullen.\n",
      "        Dit geeft ons een puntschatting van $y_0 = 65.4933 +0.1126 \\cdot 6.75 \\approx 66.2534$.\n",
      "        Daarnaast kunnen we de standaardafwijking $\\sigma$ van de storingsterm $\\varepsilon$ schatten:\n",
      "        \\begin{align*}\n",
      "            s_{\\varepsilon} &= \\sqrt{ \\frac{n}{n-2} \\cdot \\left( \\overline{y^2} - a \\cdot \\overline{y} - b \\cdot \\overline{xy} \\right) } \\\\ \n",
      "                               &= \\sqrt{ \\frac{9}{7} \\cdot \\left( 5470.5556 - 65.4933 \\cdot 73.8889 - 0.1126 \\cdot 5512.3333 \\right) } \\\\ \n",
      "                               &\\approx 3.6904. \n",
      "        \\end{align*}\n",
      "\n",
      "        Vervolgens kunnen we een puntschatting berekenen van de standaardafwijking van $Y$ voor gegeven $X = x_0$:\n",
      "        \\begin{align*}\n",
      "            s_{f} &= s_{\\varepsilon} \\cdot \\sqrt{ 1 + \\frac{1}{n} \\cdot \\left( 1 + \\frac{(x_0 - \\overline{x})^2}{\\overline{x^2} - \\overline{x}^2} \\right) } \\\\\n",
      "                    &= 3.6904 \\cdot \\sqrt{ 1 + \\frac{1}{9} \\cdot \\left( 1 + \\frac{(6.75 - 74.5556)^2}{5589.6667 - 74.5556^2} \\right) } \\\\\n",
      "                    &\\approx 15.4462.         \n",
      "        \\end{align*}\n",
      "\n",
      "        Omdat we de standaardafwijkingen geschat hebben en de storingstermen normaal verdeeld zijn, moeten we werken met de $t$-verdeling met $df = n - 2 = 7$ vrijheidsgraden.\n",
      "        De $t$-waarde die hoort bij een betrouwbaarheidsniveau $\\alpha = 0.09999999999999998$ is gelijk aan\n",
      "        \\[\n",
      "            t = \\invt(\\text{opp} = 1 - \\alpha / 2; \\text{df} = n - 2) = \\invt(\\text{opp} = 0.95; \\text{df} = 7) \\approx 1.8946.\n",
      "        \\]\n",
      "        Het \\SI{90}{\\percent}-betrouwbaarheidsinterval voor de gemiddelde $Y$ voor gegeven $X = x_0$ kan dus worden beschreven door\n",
      "        \\begin{align*}\n",
      "            &[y_0 - t \\cdot s_{f}; y_0 - t \\cdot s_{f}] \\\\ \n",
      "            &= [66.2534 - 1.8946 \\cdot 15.4462; 66.2534 + 1.8946 \\cdot 15.4462] \\\\ \n",
      "            &\\approx [36.9894; 95.5174]. \n",
      "        \\end{align*}\n",
      "        \n",
      "        Met \\SI{90}{\\percent} betrouwbaarheid ligt een toekomstige uitkomst van $Y$ voor gegeven $X = 6.75$ tussen $36.9894$ en $95.5174$.\n",
      "    \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAHFCAYAAADv3Q81AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABpW0lEQVR4nO3deVhU1f8H8PdlG/YRkNUFEFdUXHLJJbFSUQlNy1Lcl9SszDRTU1PMvVzKXCrNJdxa1FzKErdcMCTccRdwAzERUJF1zu8Pf8x3hhkQEL2M9/16nnl0zj1z7+fM3Ln3w5lzz5WEEAJERERERAQAMJM7ACIiIiKi8oQJMhERERGRDibIREREREQ6mCATEREREelggkxEREREpIMJMhERERGRDibIREREREQ6mCATEREREelggkxEREREpKPECfI///yDbt26oWrVqlCpVHB3d0eLFi0wZsyYpxFfsaxatQqSJCE+Pv6xddu2bYu2bdtqn8fHx0OSJKxateqpxfekTDFmuZw9exZ9+/ZFtWrVYG1tjYoVK6Jx48Z4//33kZ6erq03YMAA+Pj4yBdoAUuWLDH6eRr7rJ9kfy9KamoqKlasiA0bNmjLpk6dCkmSivV6U7Z7927Y29vjxo0bcodSqPzPPTo62ujy1157TZZ9OiMjA1OnTsW+fftKvQ5j+/nhw4cxdepUpKamGtQ3tl9LkoSpU6c+dlsl+f7QkynJ8ed55uPjgwEDBsi2fR7bS3dstyhJ5R07dqBLly5o27Yt5s6dC09PTyQmJiI6OhobNmzAvHnzShxAWQgODkZkZCQ8PT1L/FpPT09ERkbCz8/vKUT2dJhizM/CsWPH0KpVK9SpUwefffYZfHx88N9//+HEiRPYsGEDPv74Yzg6OsodplFLlixBxYoVDQ6ixj7rJ9nfixIWFgYvLy+8/fbb2rIhQ4agY8eOZbqd8ujVV19Fs2bN8Omnn2L16tVyh2NSMjIyEBYWBgBlmgwdPnwYYWFhGDBgACpUqKC3bMmSJQb1IyMjUbly5TLbPj05Y5+TEm3evFnWcw+P7aU7tpcoQZ47dy58fX3x559/wsLify/t2bMn5s6dW6INFyUnJweSJOltoyiurq5wdXUt1bZUKhVefPHFUr1WLnLGnJGRAVtbW1m2/TgLFy6EmZkZ9u3bBwcHB235m2++ic8//xxCCBmjKx1jn/WT7O+FSUlJwbfffosFCxbo9SpUrly5XCUdT3P/e++99/D2229j+vTpqFKlylPZhikpz991f39/gzJTO46Xdw8fPoSNjc0TrcPY56REjRo1km3bPLaX/theoiEWd+7cQcWKFY0mrmZm+qvy8fHBa6+9hs2bNyMgIADW1taoVq0avv76a716+/btgyRJ+PHHHzFmzBhUqlQJKpUKly5dAgBERETg1VdfhaOjI2xtbdGqVSvs3r1bbx3GfjITQmDu3Lnw9vaGtbU1GjdujD/++MMgbmM/7eX/9HDmzBn06tULarUa7u7uGDRoENLS0vRen5qaisGDB8PZ2Rn29vYIDg7GlStXDH7uu337NoYOHYoqVapApVLB1dUVrVq1QkRERJnEfOnSJQwcOBA1atSAra0tKlWqhJCQEJw6dcrg9WfOnEGHDh1ga2sLV1dXvPfee9ixYwckSdL7mbRt27aoV68e/v77b7Rs2RK2trYYNGgQAGDjxo3o0KEDPD09YWNjgzp16mD8+PF48OCB3rYGDBgAe3t7nDt3DkFBQbCzs4Onpydmz54NADhy5Ahat24NOzs71KxZ84l67+7cuQNHR0fY29sbXf64n5MWL16MNm3awM3NDXZ2dqhfvz7mzp2LnJwcvXq7du1C165dUblyZVhbW6N69eoYNmwY/vvvP716+fvRsWPH0L17dzg6OkKtVqNPnz64ffu2tp6Pjw/OnDmD/fv3Q5IkSJKk/am8uEMsirvvFGbVqlXIzc3V62HQbYOu/O/2zp070bhxY9jY2KB27dr44YcfHrud/O97wZ/jjbUzf985deoUOnToAAcHB7z66qsAgOzsbEyfPh21a9fWfp8GDhyo976WNNaQkBDY29vj+++/L7INCxcuhCRJ2mOUrnHjxsHKykq7Lxw7dgyvvfYa3NzcoFKp4OXlheDgYFy/fv2x71VZEEJgyZIlaNiwIWxsbODk5IQ333wTV65c0atX1Hd9z549aNu2LVxcXGBjY4OqVavijTfeQEZGBuLj47V/rIWFhWn3X91fQi5evIjQ0FDte1CnTh0sXry4yLinTp2KsWPHAgB8fX21683fb4o7xOLIkSNo1aoVrK2t4eXlhQkTJhh8nwuTv/9dunQJnTt3hr29PapUqYIxY8YgKytLr25YWBiaN28OZ2dnODo6onHjxlixYsVj/yjP3+8LewCPjktmZmZITk7Wvm7evHmQJAnvvfeetkyj0cDJyUlvuGNx48r/nmzatAmNGjWCtbW19leBpKQkDBs2DJUrV4aVlRV8fX0RFhaG3Nzcx76HhQ0P/PLLLzF//nz4+vrC3t4eLVq0wJEjR/Ree+XKFfTs2RNeXl7a4Zyvvvoqjh8/bhD34/KMzMxMjBkzBg0bNoRarYazszNatGiB3377zSBmSZLw/vvv48cff0SdOnVga2uLBg0aYPv27Xr1SpInFBxikX8cXL9+PSZOnAgvLy84OjqiXbt2OH/+vN5rhRCYOXOm9tjepEkT7Nq1q9jDV3hsL/6xvaAS9SC3aNECy5cvx8iRI9G7d280btwYlpaWhdY/fvw4Ro0ahalTp8LDwwNr167Fhx9+iOzsbHz88cd6dSdMmIAWLVpg2bJlMDMzg5ubG8LDw9GvXz907doVq1evhqWlJb799lsEBQXhzz//1L6hxoSFhSEsLAyDBw/Gm2++iWvXruGdd95BXl4eatWqVaz2vvHGG3j77bcxePBgnDp1ChMmTAAA7Qeg0WgQEhKC6OhoTJ06FY0bN0ZkZKTRny369u2LmJgYzJgxAzVr1kRqaipiYmJw586dMon55s2bcHFxwezZs+Hq6oqUlBSsXr0azZs3x7Fjx7SvT0xMRGBgIOzs7LB06VK4ublh/fr1eP/9942uNzExEX369MEnn3yCmTNnav8QunjxIjp37oxRo0bBzs4O586dw5w5cxAVFYU9e/borSMnJwfdu3fH8OHDMXbsWKxbtw4TJkxAeno6fv31V4wbNw6VK1fGokWLMGDAANSrVw8vvPCC9vW6yWJRWrRogR07dqB3794YNmwYmjVrVqIekMuXLyM0NBS+vr6wsrLCiRMnMGPGDJw7d07vS3f58mW0aNECQ4YMgVqtRnx8PObPn4/WrVvj1KlTBt+Jbt264a233sLw4cNx5swZTJ48GbGxsfjnn39gaWmJzZs3480334Rardb+JKlSqYodN/Dk+/uOHTvQqFEjg5+yC3PixAmMGTMG48ePh7u7O5YvX47BgwejevXqaNOmTYliL0p2dja6dOmCYcOGYfz48cjNzYVGo0HXrl1x4MABfPLJJ2jZsiUSEhIwZcoUtG3bFtHR0Xqfe3FjtbKyQsuWLbFjxw5Mmzat0Jj69OmDcePGYdWqVZg+fbq2PC8vD+Hh4QgJCUHFihXx4MEDtG/fHr6+vli8eDHc3d2RlJSEvXv34t69e6V+T/Ly8owmJ8aSsWHDhmHVqlUYOXIk5syZg5SUFEybNg0tW7bEiRMn4O7urq1r7LseHx+P4OBgvPTSS/jhhx9QoUIF3LhxAzt37kR2djY8PT2xc+dOdOzYEYMHD8aQIUMAQJs0x8bGomXLlqhatSrmzZsHDw8P/Pnnnxg5ciT+++8/TJkyxWgbhwwZgpSUFCxatAibNm3SDicqSY9kbGwsXn31Vfj4+GDVqlWwtbXFkiVLsG7dumKvIycnB126dMHgwYMxZswY/P333/j888+hVqvx2WefaevFx8dj2LBhqFq1KoBHifkHH3yAGzdu6NUrKH8Ila7bt2+jT58+qFSpEgCgXbt2EEJg9+7d6NWrF4BHHUc2NjbYtWuX9nXR0dFITU1Fu3btShVXTEwMzp49i0mTJsHX1xd2dnZISkpCs2bNYGZmhs8++wx+fn6IjIzE9OnTER8fj5UrVxb7vdS1ePFi1K5dGwsXLgQATJ48GZ07d0ZcXBzUajUAoHPnzsjLy8PcuXNRtWpV/Pfffzh8+LDBmPTi5BlZWVlISUnBxx9/jEqVKiE7OxsRERHo3r07Vq5ciX79+umtc8eOHTh69CimTZsGe3t7zJ07F926dcP58+dRrVo1vbqPyxOK8umnn6JVq1ZYvnw50tPTMW7cOISEhODs2bMwNzcHAEycOBGzZs3C0KFD0b17d1y7dg1DhgxBTk4Oatas+dht8Nhe/GO7AVEC//33n2jdurUAIAAIS0tL0bJlSzFr1ixx7949vbre3t5CkiRx/PhxvfL27dsLR0dH8eDBAyGEEHv37hUARJs2bfTqPXjwQDg7O4uQkBC98ry8PNGgQQPRrFkzbdnKlSsFABEXFyeEEOLu3bvC2tpadOvWTe+1hw4dEgBEYGCgtiwuLk4AECtXrtSWTZkyRQAQc+fO1Xv9iBEjhLW1tdBoNEIIIXbs2CEAiKVLl+rVmzVrlgAgpkyZoi2zt7cXo0aNEoV50pgLys3NFdnZ2aJGjRrio48+0paPHTtWSJIkzpw5o1c/KChIABB79+7VlgUGBgoAYvfu3YVuRwghNBqNyMnJEfv37xcAxIkTJ7TL+vfvLwCIX3/9VVuWk5MjXF1dBQARExOjLb9z544wNzcXo0eP1lu/n5+f8PPzKzIGIYTIzMwUr7/+unb/NDc3F40aNRITJ04UycnJenX79+8vvL29C11XXl6eyMnJEWvWrBHm5uYiJSWlyLYnJCQIAOK3337TLsvfj3TffyGEWLt2rQAgwsPDtWV169bV+4zzGfusn2R/L4ytra0YPny4QXl+G3R5e3sLa2trkZCQoC17+PChcHZ2FsOGDStyO/nfd939rLB25u87P/zwg17d9evXG+xTQghx9OhRAUAsWbKk1LFOnDhRmJmZifv37xfZju7du4vKlSuLvLw8bdnvv/8uAIht27YJIYSIjo4WAMSWLVuKXFdx5X/uRT109+nIyEgBQMybN09vPdeuXRM2Njbik08+0ZYV9l3/5ZdfBACD47iu27dvGxzv8gUFBYnKlSuLtLQ0vfL3339fWFtba79Xxj7/L774Qm8/1xUYGGiwXxeM4e233xY2NjYiKSlJW5abmytq165d6Hp15e9/P/30k155586dRa1atQp9Xf6xY9q0acLFxUV7viiOBw8eiGbNmglPT08RHx+vLa9cubIYNGiQEEKIrKwsYWdnJ8aNGycAaPftGTNmCEtLy0L33aLi8vb2Fubm5uL8+fN6rxk2bJiwt7fX+/4IIcSXX34pABicRwoq+Dnlf87169cXubm52vKoqCgBQKxfv14I8SjXACAWLlxY5PqLm2cUlJubK3JycsTgwYNFo0aN9JYBEO7u7iI9PV1blpSUJMzMzMSsWbO0ZcXNE/Lj7N+/v/Z5/nGwc+fOeq/96aefBAARGRkphBAiJSVFqFQq8fbbb+vVy/9u89he9sd2XSUaYuHi4oIDBw7g6NGjmD17Nrp27YoLFy5gwoQJqF+/vsFPzHXr1kWDBg30ykJDQ5Geno6YmBi98jfeeEPv+eHDh5GSkoL+/fsjNzdX+9BoNOjYsSOOHj1q8HN+vsjISGRmZqJ379565S1btoS3t3ex29ulSxe95wEBAcjMzNT+1LV//34AwFtvvaVXL/+vfF3NmjXT9jgdOXLE4Ge+J405NzcXM2fOhL+/P6ysrGBhYQErKytcvHgRZ8+e1dbbv38/6tWrZ9ATYyxmAHBycsIrr7xiUH7lyhWEhobCw8MD5ubmsLS0RGBgIADobQ949JNV586dtc8tLCxQvXp1eHp66o3NcnZ2hpubGxISEvRef+nSJaM/ZxekUqmwefNmxMbGYsGCBejZsydu376NGTNmoE6dOgY/XRV07NgxdOnSBS4uLto29evXD3l5ebhw4YK2XnJyMoYPH44qVarAwsIClpaW2s+oYNsBGHymb731FiwsLLB3797Htqk4nnTfSU1NRUZGBtzc3Iq9zYYNG2p7pQDA2toaNWvWNPjsykLBY8P27dtRoUIFhISE6B0bGjZsCA8PD4Of+EoSq5ubGzQaDZKSkoqMaeDAgbh+/breEKmVK1fCw8MDnTp1AgBUr14dTk5OGDduHJYtW4bY2NiSNt2oNWvW4OjRowaP1q1b69Xbvn07JElCnz599N4nDw8PNGjQwOB9MvZdb9iwIaysrDB06FCsXr3aYGhGUTIzM7F7925069YNtra2ejF07twZmZmZBj+rl6W9e/fi1Vdf1eslNzc3N/ipuSiSJCEkJESvLCAgwGDf2bNnD9q1awe1Wq09dnz22We4c+eO3tCIouTl5eHtt9/G2bNn8fvvv+t9d1999VXtvnb48GFkZGRg9OjRqFixorYXOSIiAi1atICdnV2p4goICDDokdy+fTtefvlleHl56X1++ft4/jmwpIKDg7U9pPnbBqB9X52dneHn54cvvvgC8+fPx7Fjx6DRaIyuq7h5xs8//4xWrVrB3t5ee9xesWKF0WP2yy+/rHcdi7u7u9FzE/D4PKEoxl4L/O99OHLkCLKysgxyjBdffLFYM9bw2P4/xT226yrVPMhNmjTBuHHj8PPPP+PmzZv46KOPEB8fb3ChnoeHh8Fr88t0hxYAMLgi/9atWwAeXWBlaWmp95gzZw6EEEhJSTEaX/66i9p+cbi4uOg9z//Z++HDh9rtWFhYwNnZWa+e7gE538aNG9G/f38sX74cLVq0gLOzM/r166f9sJ405tGjR2Py5Ml4/fXXsW3bNvzzzz84evQoGjRooI03fzvG4jNWBhh+LgBw//59vPTSS/jnn38wffp07Nu3D0ePHsWmTZsAQG97AGBrawtra2u9MisrK4P3Lb88MzPzse0tSp06dTBq1CiEh4fj6tWrmD9/Pu7cuYPJkycX+pqrV6/ipZdewo0bN/DVV19p/xDMHyuZ3yaNRoMOHTpg06ZN+OSTT7B7925ERUVpT/QF2w4Yfn4WFhZwcXEx+A6U1pPuO/kxF/yMilLwuwE8+n4Ya/+TsLW1Nbj6+9atW0hNTYWVlZXBsSEpKcngD/WSxJr/HjyuHZ06dYKnp6f2J+a7d+9i69at6Nevn/bEr1arsX//fjRs2BCffvop6tatCy8vL0yZMqXY42CNqVOnDpo0aWLwyP9pOt+tW7cghIC7u7vB+3TkyBGD98nYd93Pzw8RERFwc3PDe++9Bz8/P/j5+eGrr756bJx37txBbm4uFi1aZLD9/D+YC8ZQlu7cufPE5wBjxy6VSqV3jIqKikKHDh0AAN9//z0OHTqEo0ePYuLEiQAevy/lGz58OHbu3IlffvkFDRs21FvWrl07XL16FRcvXkRERAQaNWoENzc3vPLKK4iIiMDDhw9x+PBhveEVJY3L2Od/69YtbNu2zeDzq1u3LoDSf36PO7dKkoTdu3cjKCgIc+fORePGjeHq6oqRI0caDE8qTp6xadMmvPXWW6hUqRLCw8MRGRmJo0ePYtCgQUbPNyU5ZjyuLUUpTo4BGD8/F3bO1sVj+/8U99iuq0RjkI2xtLTElClTsGDBApw+fVpvmbFMPb+sYMMKDhavWLEiAGDRokWFXp1c2A6Sv+7Ctl9Wc4W6uLggNzcXKSkpesmese1WrFgRCxcuxMKFC3H16lVs3boV48ePR3JyMnbu3PnEMeeP1545c6Ze+X///ac39sjFxUX7x0fBbRhj7MK2PXv24ObNm9i3b5+21xiA0flK5SZJEj766CNMmzbNYP/UtWXLFjx48ACbNm3S67nRvSAEAE6fPo0TJ05g1apV6N+/v7a8qB7upKQk7XhC4FFv/507d4x+uUvjSfed/NcX9gdnWco/SBW8yKmwE62x/a9ixYpwcXHBzp07jb5Gt+enpPLfg/zjT2HMzc3Rt29ffP3110hNTcW6deuQlZWFgQMH6tWrX78+NmzYACEETp48iVWrVmHatGmwsbHB+PHjSx1ncVSsWBGSJOHAgQNGx7QXLCvsItaXXnoJL730EvLy8hAdHY1FixZh1KhRcHd3R8+ePQvdvpOTk/Z90r2YTJevr28JWlQyLi4uRZ6DysqGDRtgaWmJ7du36yUiW7ZsKfY6pk6diuXLl2PlypXapFZX/vU2ERER2LVrF9q3b68tnzRpEv7++29kZWXpJcgljauw71pAQABmzJhh9DVeXl7FbmNJeXt7Y8WKFQCACxcu4KeffsLUqVORnZ2NZcuWaesVJ88IDw+Hr68vNm7cqNfOgseh8iY//sLO2Ty2F19xj+26StSDnJiYaLQ8/yeKgl+WM2fO4MSJE3pl69atg4ODAxo3blzktlq1aoUKFSogNjbWaG9JkyZNYGVlZfS1L774IqytrbF27Vq98sOHD5fpzwT5yeHGjRv1ynUn4zamatWqeP/999G+fXvtT0BPGrMkSQYnvB07dhhMjh0YGIjTp08b/Nz7uJgLbgswPMF+++23xV7H01DY/nnz5k2kp6cXeTA31iYhhMFVr6Vpe8HP9KeffkJubq7eFchP8hf6k+47VlZWqFatGi5fvlyq7ZdE/gH95MmTeuVbt24t9jpee+013LlzB3l5eUaPC8W9CNeYK1euwMXFpVi9MwMHDkRmZibWr1+PVatWoUWLFqhdu7bRupIkoUGDBliwYAEqVKhgMMTsaXjttdcghMCNGzeMvk/169cv0frMzc3RvHlz7a8q+W0orMfM1tYWL7/8Mo4dO4aAgACjMRT1R2JJeuKMefnll7F792695CIvL8/geP2k8qck1R0y8PDhQ/z444/Fev2KFSsQFhaGadOmFXozCU9PT/j7++PXX3/Fv//+q02Q27dvj9u3b2P+/PlwdHRE06ZNyywu4NE+dPr0afj5+Rn9/J5mgqyrZs2amDRpEurXr2/w3SlOniFJEqysrPSSsqSkJKOzWJQnzZs3h0qlMthnjxw5wmN7CZXk2J6vRD3IQUFBqFy5MkJCQlC7dm1oNBocP34c8+bNg729PT788EO9+l5eXujSpQumTp0KT09PhIeHY9euXZgzZ85j57uzt7fHokWL0L9/f6SkpODNN9+Em5sbbt++jRMnTuD27dtYunSp0dc6OTnh448/xvTp0zFkyBD06NED165d017lWlY6duyIVq1aYcyYMUhPT8cLL7yAyMhIrFmzBsD/pr5LS0vDyy+/jNDQUNSuXRsODg44evQodu7cie7du5dJzK+99hpWrVqF2rVrIyAgAP/++y+++OILg3kOR40ahR9++AGdOnXCtGnT4O7ujnXr1uHcuXN6MRelZcuWcHJywvDhwzFlyhRYWlpi7dq1BgepslK9enUARffSAsDQoUORmpqKN954A/Xq1YO5uTnOnTuHBQsWwMzMDOPGjSv0te3bt4eVlRV69eqFTz75BJmZmVi6dCnu3r2rV6927drw8/PD+PHjIYSAs7Mztm3bpnc1eUGbNm2ChYUF2rdvr53FokGDBnrjyvJ7Gjdu3Ki9C2BxE5iy2N/btm1bomnhSsvDwwPt2rXDrFmz4OTkBG9vb+zevVs7PKc4evbsibVr16Jz58748MMP0axZM1haWuL69evYu3cvunbtim7dupUqviNHjiAwMLBYd5iqXbs2WrRogVmzZuHatWv47rvv9JZv374dS5Ysweuvv45q1apBCIFNmzYhNTVVm+AAj3oB9+/fX6xps0qiVatWGDp0KAYOHIjo6Gi0adMGdnZ2SExMxMGDB1G/fn28++67Ra5j2bJl2LNnD4KDg1G1alVkZmZqr87P7610cHCAt7c3fvvtN7z66qtwdnZGxYoV4ePjg6+++gqtW7fGSy+9hHfffRc+Pj64d+8eLl26hG3bthnMeKMrf///6quv0L9/f1haWqJWrVrF7kWaNGkStm7dildeeQWfffYZbG1tsXjx4kKvXSmt4OBgzJ8/H6GhoRg6dCju3LmDL7/8slgz0URGRmL48OFo1aoV2rdvbzAmW/fX01dffRWLFi2CjY0NWrVqBeBRD7yvry/++usvdOnSRW8K1ieJK9+0adOwa9cutGzZEiNHjkStWrWQmZmJ+Ph4/P7771i2bNlTmUv35MmTeP/999GjRw/UqFEDVlZW2LNnD06ePGnwy0tx8oz8KexGjBihneXn888/h6enJy5evFjm8ZcVZ2dnjB49Wnu87NatG65fv46wsDB4enoW63zNY/sjJTm2axX7cj4hxMaNG0VoaKioUaOGsLe3F5aWlqJq1aqib9++IjY2Vq+ut7e3CA4OFr/88ouoW7eusLKyEj4+PmL+/Pl69fKvfPz555+NbnP//v0iODhYODs7C0tLS1GpUiURHBysV7/gVf1CPJpdYNasWaJKlSrCyspKBAQEiG3bthV6Va2xWSxu376tF4ux7aSkpIiBAweKChUqCFtbW9G+fXtx5MgRAUB89dVXQohHsysMHz5cBAQECEdHR2FjYyNq1aolpkyZoneV7ZPEfPfuXTF48GDh5uYmbG1tRevWrcWBAweMXu19+vRp0a5dO2FtbS2cnZ3F4MGDxerVqw1moAgMDBR169Y1+rkcPnxYtGjRQtja2gpXV1cxZMgQERMTY/RqVTs7O4PXF7bu/P2mYFlRM07k+/PPP8WgQYOEv7+/UKvVwsLCQnh6eoru3btrrwrWjavgOrdt2yYaNGggrK2tRaVKlcTYsWPFH3/8YXBlbmxsrGjfvr1wcHAQTk5OokePHuLq1asGV9Hn70f//vuvCAkJEfb29sLBwUH06tVL3Lp1S2/b8fHxokOHDsLBwUFvNoKiZrHQvcq9uPtOYXbv3i0AiKioKL3ywq50LvgZCWF8ZgFjEhMTxZtvvimcnZ2FWq0Wffr00c74UJx9R4hHM6F8+eWX2s/L3t5e1K5dWwwbNkxcvHixVLFeunTJ6BXURfnuu+8EAGFjY2MwU8O5c+dEr169hJ+fn7CxsRFqtVo0a9ZMrFq1yiCW4hyK8z/3o0ePGl0eHBxs9Hvyww8/iObNmws7OzthY2Mj/Pz8RL9+/UR0dLReDMa+j5GRkaJbt27C29tbqFQq4eLiIgIDA8XWrVv16kVERIhGjRoJlUolAOhdsR8XFycGDRokKlWqJCwtLYWrq6to2bKlmD59ul6dgp+/EEJMmDBBeHl5CTMzM73vYWGzWEydOlWv7NChQ+LFF18UKpVKeHh4iLFjx2o/s+LMYmFs/zP2nfjhhx9ErVq1hEqlEtWqVROzZs0SK1aseOx2Hjczia7ffvtNABDt27fXK3/nnXcEAPH1118brL+4cRX2PRHi0SwlI0eOFL6+vsLS0lI4OzuLF154QUycOPGxMwIUdu764osvDOrqHj9v3bolBgwYIGrXri3s7OyEvb29CAgIEAsWLNCb/aK4eYYQQsyePVv4+PgIlUol6tSpI77//nujnyUA8d577xm8vuBMFCXJEwqbxaJg3mPse6DRaMT06dNF5cqVtcf27du3iwYNGhjMXGQMj+2lO7YLIUSJEuSSKOoL97zLn8br0KFDcodSbO+8846wt7cXWVlZcofy3CjsAPqkFi5cKAAYTK34pOrXr290OiClmDRpkqhatarIycmROxQqodTUVAFALFq0SO5Q6BlSap5x5coVYWVlJWbMmFGs+jy2l+7Y/sQX6Snd+vXrcePGDdSvXx9mZmY4cuQIvvjiC7Rp0wYtW7aUOzyjpk2bBi8vL1SrVg3379/H9u3bsXz5ckyaNKnQcd0kv7S0NERGRmLVqlWoV69eoXcMLK38yfAnTpxYrm5B+iykpqZi8eLFWLRoUbFvcU/lw5EjR7RjNFu0aCFzNERl68SJE1i/fj1atmwJR0dHnD9/HnPnzoWjoyMGDx5crHXw2F66YzvPBE/IwcEBGzZswPTp0/HgwQN4enpiwIABenfYKm8sLS3xxRdf4Pr168jNzUWNGjUwf/58gzHkVL4cO3YM3bp1Q0BAgPbq7rLUsWNHfPHFF4iLi1PcQTQuLg4TJkxAaGio3KFQCYWGhiIvLw/z5s3TuwMn0fPAzs4O0dHRWLFiBVJTU6FWq9G2bVvMmDGj2Bec8dheumO7JMRjbhZPRERERKQgpbpRCBERERHR84oJMhERERGRDibIREREREQ6eJGeCdFoNLh58yYcHBxKNtk1ERERyUYIgXv37sHLy6tYN/gg+TFBNiE3b95ElSpV5A6DiIiISuHatWuKm0nCVDFBNiH5t1i9du0aHB0dZY6GiIiIiiM9PR1VqlQp9q3SSX5MkE1I/rAKR0dHJshEREQmhsMjTQcHwhARERER6WCCTERERESkgwkyEREREZEOJshERERERDqYIBMRERER6WCCTERERESkgwkyEREREZEOJshERERERDqYIBMRERER6eCd9IiIiKjcydMIRMWlIPleJtwcrNHM1xnmZrwTHT0b7EEuI7m5uZg0aRJ8fX1hY2ODatWqYdq0adBoNNo6QghMnToVXl5esLGxQdu2bXHmzBkZoyYiIip/dp5OROs5e9Dr+yP4cMNx9Pr+CFrP2YOdpxPlDo0UgglyGZkzZw6WLVuGb775BmfPnsXcuXPxxRdfYNGiRdo6c+fOxfz58/HNN9/g6NGj8PDwQPv27XHv3j0ZIyciIio/dp5OxLvhMUhMy9QrT0rLxLvhMUyS6ZlgglxGIiMj0bVrVwQHB8PHxwdvvvkmOnTogOjoaACPeo8XLlyIiRMnonv37qhXrx5Wr16NjIwMrFu3TuboiYiI5JenEQjbFgthZFl+Wdi2WORpjNUgKjtMkMtI69atsXv3bly4cAEAcOLECRw8eBCdO3cGAMTFxSEpKQkdOnTQvkalUiEwMBCHDx82us6srCykp6frPYiIiJ5XUXEpBj3HugSAxLRMRMWlPLugSJF4kV4ZGTduHNLS0lC7dm2Ym5sjLy8PM2bMQK9evQAASUlJAAB3d3e917m7uyMhIcHoOmfNmoWwsLCnGzgREVE5kXyv8OS4NPWISos9yGVk48aNCA8Px7p16xATE4PVq1fjyy+/xOrVq/XqSZL+FbhCCIOyfBMmTEBaWpr2ce3atacWPxERkdzcHKzLtB5RabEHuYyMHTsW48ePR8+ePQEA9evXR0JCAmbNmoX+/fvDw8MDwKOeZE9PT+3rkpOTDXqV86lUKqhUqqcfPBERUTnQzNcZnmprJKVlGh2HLAHwUD+a8o3oaWIPchnJyMiAmZn+22lubq6d5s3X1xceHh7YtWuXdnl2djb279+Pli1bPtNYiYiIyiNzMwlTQvwBPEqGdeU/nxLiz/mQ6aljglxGQkJCMGPGDOzYsQPx8fHYvHkz5s+fj27dugF4NLRi1KhRmDlzJjZv3ozTp09jwIABsLW1RWhoqMzRExERlQ8d63liaZ/G8FDrD6PwUFtjaZ/G6FjPs5BXEpUdSQjBuVLKwL179zB58mRs3rwZycnJ8PLyQq9evfDZZ5/BysoKwKPxxmFhYfj2229x9+5dNG/eHIsXL0a9evWKtY309HSo1WqkpaXB0dHxaTaHiIhIVs/TnfR4/jY9TJBNCL9gREREpofnb9PDIRZERERERDqYIBMRERER6WCCTERERESkgwkyEREREZEOJshERERERDqYIBMRERER6WCCTERERESkgwkyEREREZEOJshERERERDqYIBMRERER6WCCTERERESkgwkyEREREZEOJshERERERDqYIBMRERER6WCCTERERESkgwkyEREREZEOJshERERERDqYIBMRERER6WCCTERERESkgwkyEREREZEOJshERERERDos5A5ATvHx8Thw4ADi4+ORkZEBV1dXNGrUCC1atIC1tbXc4RERERGRDBSZIK9btw5ff/01oqKi4ObmhkqVKsHGxgYpKSm4fPkyrK2t0bt3b4wbNw7e3t5yh0tEREREz5DiEuTGjRvDzMwMAwYMwE8//YSqVavqLc/KykJkZCQ2bNiAJk2aYMmSJejRo4dM0RIRERHRsyYJIYTcQTxLO3bsQHBwcLHq/vfff4iLi0PTpk2fclTFk56eDrVajbS0NDg6OsodDhERERUDz9+mR3E9yMVNjgGgYsWKqFix4lOMhoiIiIjKG8UlyAVpNBpcunQJycnJ0Gg0esvatGkjU1REREREJBdFJ8hHjhxBaGgoEhISUHCkiSRJyMvLkykyIiIiIpKLohPk4cOHo0mTJtixYwc8PT0hSZLcIRERERGRzBSdIF+8eBG//PILqlevLncoRERERFROKPpOes2bN8elS5fkDoOIiIiIyhFF9yB/8MEHGDNmDJKSklC/fn1YWlrqLQ8ICJApMiIiIiKSi+LmQdZlZmbYgS5JEoQQ5fIiPc6jSEREZHp4/jY9iu5BjouLkzsEIiIiIipnFJ0ge3t7yx0CEREREZUzir5IDwB+/PFHtGrVCl5eXkhISAAALFy4EL/99pvMkRERERGRHBSdIC9duhSjR49G586dkZqaqh1zXKFCBSxcuFDe4IiIiIhIFopOkBctWoTvv/8eEydOhLm5uba8SZMmOHXqlIyREREREZFcFJ0gx8XFoVGjRgblKpUKDx48kCEiIiIiIpKbohNkX19fHD9+3KD8jz/+gL+//7MPiIiIiIhkp+hZLMaOHYv33nsPmZmZEEIgKioK69evx6xZs7B8+XK5wyMiIiIiGSg6QR44cCByc3PxySefICMjA6GhoahUqRK++uor9OzZU+7wiIiIiEgGik2Qc3NzsXbtWoSEhOCdd97Bf//9B41GAzc3N7lDIyIiIiIZKXYMsoWFBd59911kZWUBACpWrMjkmIiIiIiUmyADQPPmzXHs2DG5wyAiIiKickSxQywAYMSIERgzZgyuX7+OF154AXZ2dnrLAwICZIqMiIiIiOQiCSGE3EHIxczMsANdkiQIISBJkvbOeuVFeno61Go10tLS4OjoKHc4REREVAw8f5seRfcgx8XFyR0CEREREZUzik6Qvb295Q6BiIiIiMoZRSfIa9asKXJ5v379nlEkRFSe5GkEouJSkHwvE24O1mjm6wxzM0nusIiI6BlR9BhkJycnvec5OTnIyMiAlZUVbG1tkZKSUux1+fj4ICEhwaB8xIgRWLx4Me7fv4/x48djy5YtuHPnDnx8fDBy5Ei8++67xd4GxzARPX07TycibFssEtMytWWeamtMCfFHx3qeMkZGRKaK52/To+hp3u7evav3uH//Ps6fP4/WrVtj/fr1JVrX0aNHkZiYqH3s2rULANCjRw8AwEcffYSdO3ciPDwcZ8+exUcffYQPPvgAv/32W5m3i4hKZ+fpRLwbHqOXHANAUlom3g2Pwc7TiTJFRkREz5KiE2RjatSogdmzZ+PDDz8s0etcXV3h4eGhfWzfvh1+fn4IDAwEAERGRqJ///5o27YtfHx8MHToUDRo0ADR0dFPoxlEVEJ5GoGwbbEw9pNaflnYtljkaRT7oxsRkWIwQTbC3NwcN2/eLPXrs7OzER4ejkGDBkGSHo1bbN26NbZu3YobN25ACIG9e/fiwoULCAoKKnQ9WVlZSE9P13sQ0dMRFZdi0HOsSwBITMtEVFzxh14REZFpUvRFelu3btV7LoRAYmIivvnmG7Rq1arU692yZQtSU1MxYMAAbdnXX3+Nd955B5UrV4aFhQXMzMywfPlytG7dutD1zJo1C2FhYaWOg4iKL/le4clxaeoREZHpUnSC/Prrr+s9lyQJrq6ueOWVVzBv3rxSr3fFihXo1KkTvLy8tGVff/01jhw5gq1bt8Lb2xt///03RowYAU9PT7Rr187oeiZMmIDRo0drn6enp6NKlSqljouICufmYF2m9YiIyHQpOkHWaDRlvs6EhARERERg06ZN2rKHDx/i008/xebNmxEcHAzg0W2sjx8/ji+//LLQBFmlUkGlUpV5jERkqJmvMzzV1khKyzQ6DlkC4KF+NOUbERE93zgGuYytXLkSbm5u2kQYeDR9XE5OjsGtrc3NzZ9Kkk5EJWduJmFKiD+AR8mwrvznU0L8OR8yEZECMEEuQxqNBitXrkT//v1hYfG/znlHR0cEBgZi7Nix2LdvH+Li4rBq1SqsWbMG3bp1kzFiItLVsZ4nlvZpDA+1/jAKD7U1lvZpzHmQiYgUQtE3Cilrf/31F4KCgnD+/HnUrFlTb1lSUhImTJiAv/76CykpKfD29sbQoUPx0UcfaWe6eBxONE70bPBOekRUlnj+Nj1MkE0Iv2BERESmh+dv08MhFkREREREOhQ9iwUApKamIioqCsnJyQYXzPXr10+mqIiIiIhILopOkLdt24bevXvjwYMHcHBw0BsLLEkSE2QiIiIiBVL0EIsxY8Zg0KBBuHfvHlJTU3H37l3tIyWFt5MlIiIiUiJFJ8g3btzAyJEjYWtrK3coRERERFROKDpBDgoKQnR0tNxhEBEREVE5ougxyMHBwRg7dixiY2NRv359WFpa6i3v0qWLTJERERERkVwUPQ9ywVs/65IkCXl5ec8wmsfjPIpERESmh+dv06PoHuSC07oRERERESl6DDIRERERUUGK60H++uuvMXToUFhbW+Prr78usu7IkSOfUVREREREVF4obgyyr68voqOj4eLiAl9f30LrSZKEK1euPMPIHo9jmIiIiEwPz9+mR3E9yHFxcUb/T0REREQEcAwyEREREZEexSXIs2fPRkZGRrHq/vPPP9ixY8dTjoiIiIiIyhPFJcixsbGoWrUq3n33Xfzxxx+4ffu2dllubi5OnjyJJUuWoGXLlujZsyfHChEREREpjOLGIK9ZswYnT57E4sWL0bt3b6SlpcHc3BwqlUrbs9yoUSMMHToU/fv3h0qlkjliIiIiInqWFDeLhS4hBE6ePIn4+Hg8fPgQFStWRMOGDVGxYkW5QzOKV8ESERGZHp6/TY/iepB1SZKEBg0aoEGDBnKHQkRERETlhOLGIBMRERERFYUJMhERERGRDibIREREREQ6mCATEREREelggkxEREREpEPRs1h069YNkiQZlEuSBGtra1SvXh2hoaGoVauWDNERERERkRwU3YOsVquxZ88exMTEaBPlY8eOYc+ePcjNzcXGjRvRoEEDHDp0SOZIiYiIiOhZUXQPsoeHB0JDQ/HNN9/AzOzR3woajQYffvghHBwcsGHDBgwfPhzjxo3DwYMHZY6WiIiIiJ4FRd9Jz9XVFYcOHULNmjX1yi9cuICWLVviv//+w6lTp/DSSy8hNTVVniB18E48REREpofnb9Oj6CEWubm5OHfunEH5uXPnkJeXBwCwtrY2Ok6ZiIiIiJ5Pih5i0bdvXwwePBiffvopmjZtCkmSEBUVhZkzZ6Jfv34AgP3796Nu3boyR0pEREREz4qiE+QFCxbA3d0dc+fOxa1btwAA7u7u+OijjzBu3DgAQIcOHdCxY0c5wyQiIiKiZ0jRY5B1paenA0C5HhvEMUxERESmh+dv06PoHmRd3GGJiIiICFD4RXq3bt1C37594eXlBQsLC5ibm+s9iIiIiEh5FN2DPGDAAFy9ehWTJ0+Gp6cnZ6sgIiIiImUnyAcPHsSBAwfQsGFDuUMhIiIionJC0UMsqlSpAl6jSERERES6FJ0gL1y4EOPHj0d8fLzcoRARERFROaHoIRZvv/02MjIy4OfnB1tbW1haWuotT0lJkSkyIiIiIpKLohPkhQsXyh0CEREREZUzik6Q+/fvL3cIRERERFTOKC5BTk9P194UJP/ueYXhzUOIiIiIlEdxCbKTkxMSExPh5uaGChUqGJ37WAgBSZKQl5cnQ4REREREJCfFJch79uyBs7MzAGDv3r0yR0NERERE5Y0kOBGwyUhPT4darUZaWhqHfxAREZkInr9Nj+J6kAtKTU1FVFQUkpOTodFo9Jb169dPpqiIiIiISC6KTpC3bduG3r1748GDB3BwcNAbjyxJEhNkIiIiIgVS9J30xowZg0GDBuHevXtITU3F3bt3tQ/eJISIiIhImRSdIN+4cQMjR46Era2t3KEQERERUTmh6AQ5KCgI0dHRcodBREREROWIoscgBwcHY+zYsYiNjUX9+vVhaWmpt7xLly7FXpePjw8SEhIMykeMGIHFixcDAM6ePYtx48Zh//790Gg0qFu3Ln766SdUrVr1yRpCRERERGVG0dO8mZkV3oFe0huF3L59W6/+6dOn0b59e+zduxdt27bF5cuX0axZMwwePBi9evWCWq3G2bNn0bRpU7i5uRVrG5wmhoiIyPTw/G16FJ0gP02jRo3C9u3bcfHiRUiShJ49e8LS0hI//vhjqdfJLxgREZHp4fnb9Ch6DPLTkp2djfDwcAwaNAiSJEGj0WDHjh2oWbMmgoKC4ObmhubNm2PLli1FricrKwvp6el6DyIiIiJ6uhQ9BhkAdu/ejd27dxu9UcgPP/xQqnVu2bIFqampGDBgAAAgOTkZ9+/fx+zZszF9+nTMmTMHO3fuRPfu3bF3714EBgYaXc+sWbMQFhZWqhiIiIiIqHQUPcQiLCwM06ZNQ5MmTeDp6al3oxAA2Lx5c6nWGxQUBCsrK2zbtg0AcPPmTVSqVAm9evXCunXrtPW6dOkCOzs7rF+/3uh6srKykJWVpX2enp6OKlWq8CcaIiIiE8IhFqZH0T3Iy5Ytw6pVq9C3b98yW2dCQgIiIiKwadMmbVnFihVhYWEBf39/vbp16tTBwYMHC12XSqWCSqUqs9iIiIiI6PEUPQY5OzsbLVu2LNN1rly5Em5ubggODtaWWVlZoWnTpjh//rxe3QsXLsDb27tMt09ERERET0bRCfKQIUP0hjw8KY1Gg5UrV6J///6wsNDvnB87diw2btyI77//HpcuXcI333yDbdu2YcSIEWW2fSIiIiJ6cooeYpGZmYnvvvsOERERCAgIMLhRyPz580u0voiICFy9ehWDBg0yWNatWzcsW7YMs2bNwsiRI1GrVi38+uuvaN269RO1gYiIiIjKlqIv0nv55ZcLXSZJEvbs2fMMo3k8DvInIiIyPTx/mx5F9yDv3btX7hCIiIiIqJxR9BhkIiIiIqKCFN2DDABHjx7Fzz//jKtXryI7O1tvme5UbURERESkDIruQd6wYQNatWqF2NhYbN68GTk5OYiNjcWePXugVqvlDo+IiIiIZKDoBHnmzJlYsGABtm/fDisrK3z11Vc4e/Ys3nrrLVStWlXu8IiIiIhIBopOkC9fvqy9oYdKpcKDBw8gSRI++ugjfPfddzJHR0RERERyUHSC7OzsjHv37gEAKlWqhNOnTwMAUlNTkZGRIWdoRERERCQTRV+k99JLL2HXrl2oX78+3nrrLXz44YfYs2cPdu3ahVdffVXu8IiIiIhIBopOkL/55htkZmYCACZMmABLS0scPHgQ3bt3x+TJk2WOjoiIiIjkoOg76Zka3omHiIjI9PD8bXoU3YMMAHl5edi8eTPOnj0LSZJQp04ddO3aFRYWin9riIiIiBRJ0Vng6dOn0bVrVyQlJaFWrVoAgAsXLsDV1RVbt25F/fr1ZY6QiIiIiJ41Rc9iMWTIENStWxfXr19HTEwMYmJicO3aNQQEBGDo0KFyh0dEREREMlB0D/KJEycQHR0NJycnbZmTkxNmzJiBpk2byhgZEREREclF0T3ItWrVwq1btwzKk5OTUb16dRkiIiIiIiK5KTpBnjlzJkaOHIlffvkF169fx/Xr1/HLL79g1KhRmDNnDtLT07UPIiIiIlIGRU/zZmb2v78PJEkCAOS/HbrPJUlCXl7esw+wAE4TQ0REZHp4/jY9ih6DvHfvXrlDICIiIqJyRtEJcmBgoNwhEBEREVE5o+gxyDt37sTBgwe1zxcvXoyGDRsiNDQUd+/elTEyopLJ0whEXr6D347fQOTlO8jTKHbkFBER0RNTdII8duxY7QV4p06dwujRo9G5c2dcuXIFo0ePljk6ouLZeToRrefsQa/vj+DDDcfR6/sjaD1nD3aeTpQ7NCIiIpOk6AQ5Li4O/v7+AIBff/0VISEhmDlzJpYsWYI//vhD5uiIHm/n6US8Gx6DxLRMvfKktEy8Gx7DJJmIiKgUFJ0gW1lZISMjAwAQERGBDh06AACcnZ05tRuVe3kagbBtsTA2mCK/LGxbLIdbEBERlZCiL9Jr3bo1Ro8ejVatWiEqKgobN24EAFy4cAGVK1eWOTqiokXFpRj0HOsSABLTMhEVl4IWfi7PLjAiIiITp+ge5G+++QYWFhb45ZdfsHTpUlSqVAkA8Mcff6Bjx44yR0dUtOR7hSfHpalHREREjyi6B7lq1arYvn27QfmCBQtkiIaoZNwcrMu0HhERET2i6AQZADQaDS5duoTk5GRoNBq9ZW3atJEpKqLHa+brDE+1NZLSMo2OQ5YAeKit0czX+VmHRkREZNIUnSAfOXIEoaGhSEhIQME7bpeX20sTFcbcTMKUEH+8Gx4DCdBLkqX//3dKiD/MzSQjryYiIqLCKHoM8vDhw9GkSROcPn0aKSkpuHv3rvaRkpIid3hEj9WxnieW9mkMD7X+MAoPtTWW9mmMjvU8ZYqMiIjIdEmiYNepgtjZ2eHEiROoXr263KEUS3p6OtRqNdLS0uDo6Ch3OFSO5GkEouJSkHwvE24Oj4ZVsOeYiKh84Pnb9Ch6iEXz5s1x6dIlk0mQiQpjbiZxKjciIqIyougE+YMPPsCYMWOQlJSE+vXrw9LSUm95QECATJERERERkVwUPcTCzMxwCLYkSRBClMuL9PgTDRERkenh+dv0KLoHOS4uTu4QiIiIiKicUXSC7O3tLXcIRERERFTOKC5B3rp1Kzp16gRLS0ts3bq1yLpdunR5RlERERERUXmhuDHIZmZmSEpKgpubm9ExyPk4BpmIiIjKAs/fpkdxPci6t5MueGtpIiIiIiJF30mPiIiIiKggJshERERERDqYIBMRERER6WCCTERERESkgwkyEREREZEOxSfIly9fxqRJk9CrVy8kJycDAHbu3IkzZ87IHBkRERERyUHRCfL+/ftRv359/PPPP9i0aRPu378PADh58iSmTJkic3REREREJAdFJ8jjx4/H9OnTsWvXLlhZWWnLX375ZURGRsoYGRERERHJRdEJ8qlTp9CtWzeDcldXV9y5c0eGiIiIiIhIbopOkCtUqIDExESD8mPHjqFSpUoyREREREREclN0ghwaGopx48YhKSkJkiRBo9Hg0KFD+Pjjj9GvXz+5wyMiIiIiGUhCCCF3EHLJycnBgAEDsGHDBgghYGFhgby8PISGhmLVqlUwNzeXO0Q96enpUKvVSEtLg6Ojo9zhEJGJytMIRMWlIPleJtwcrNHM1xnmZpLcYRHJ6ml+L3j+Nj2KTZCFELh69SpcXV2RlJSEmJgYaDQaNGrUCDVq1Cjx+nx8fJCQkGBQPmLECCxevFivbNiwYfjuu++wYMECjBo1qtjb4BeMiJ7UztOJCNsWi8S0TG2Zp9oaU0L80bGep4yREcnnaX8veP42PRZyByAXIQRq1KiBM2fOoEaNGqhWrdoTre/o0aPIy8vTPj99+jTat2+PHj166NXbsmUL/vnnH3h5eT3R9oiISmrn6US8Gx6Dgr0iSWmZeDc8Bkv7NGaSTIrD7wUZo9gxyGZmZqhRo0aZzVbh6uoKDw8P7WP79u3w8/NDYGCgts6NGzfw/vvvY+3atbC0tCyT7RIRFUeeRiBsW6xBEgBAWxa2LRZ5GkX+qEgKxe8FFUaxCTIAzJ07F2PHjsXp06fLdL3Z2dkIDw/HoEGDIEmPxi9pNBr07dsXY8eORd26dYu1nqysLKSnp+s9iIhKIyouRe/n44IEgMS0TETFpTy7oIhkxu8FFUaxQywAoE+fPsjIyECDBg1gZWUFGxsbveUpKaX7QmzZsgWpqakYMGCAtmzOnDmwsLDAyJEji72eWbNmISwsrFQxEBHpSr5XeBJQmnpEzwN+L6gwik6QFy5c+FTWu2LFCnTq1Ek7zvjff//FV199hZiYGG2PcnFMmDABo0eP1j5PT09HlSpVyjxeInr+uTlYl2k9oucBvxdUGEUnyP379y/zdSYkJCAiIgKbNm3Slh04cADJycmoWrWqtiwvLw9jxozBwoULER8fb3RdKpUKKpWqzGMkIuVp5usMT7U1ktIyjY63lAB4qB9NbUWkFPxeUGEUPQZZ18OHD8tkvO/KlSvh5uaG4OBgbVnfvn1x8uRJHD9+XPvw8vLC2LFj8eeff5ZVE4iICmVuJmFKiD+ARyd9XfnPp4T4cz5kUhR+L6gwik6QHzx4gPfffx9ubm6wt7eHk5OT3qOkNBoNVq5cif79+8PC4n+d8y4uLqhXr57ew9LSEh4eHqhVq1ZZNomIqFAd63liaZ/G8FDr/1zsobbmVFakWPxekDGKHmLxySefYO/evViyZAn69euHxYsX48aNG/j2228xe/bsEq8vIiICV69exaBBg55CtERET65jPU+09/fgnfSIdPB7QQUp9k56AFC1alWsWbMGbdu2haOjI2JiYlC9enX8+OOPWL9+PX7//Xe5Q9TDO/EQERGZHp6/TY+ih1ikpKTA19cXAODo6Kid1q1169b4+++/5QyNiIiIiGSi6AS5WrVq2hkk/P398dNPPwEAtm3bhgoVKsgXGBERERHJRtEJ8sCBA3HixAkAj+YcXrJkCVQqFT766COMHTtW5uiIiIiISA6KHoNc0NWrVxEdHQ0/Pz80aNBA7nAMcAwTERGR6eH52/QoehaLjIwM2Nraap9XrVpV72YeRERERKQ8ik6QK1SogCZNmqBt27YIDAxE69atYWdnJ3dYRERERCQjRY9B3r9/P7p06YKYmBj06NEDTk5OePHFFzF+/Hj88ccfcodHRERERDLgGOT/l5eXh6NHj2LZsmVYu3YtNBoN8vLy5A5LD8cwERERmR6ev02PoodYAMC5c+ewb98+7N+/H/v27UNOTg5CQkIQGBgod2hEREREJANFJ8geHh7IycnBK6+8grZt2+LTTz9F/fr15Q6LiIiIiGSk6DHIHh4euH//Pq5evYqrV6/i+vXruH//vtxhEREREZGMFJ0gHz9+HLdu3cLEiRORm5uLyZMnw9XVFc2bN8f48ePlDo+IiIiIZMCL9P5fSkoK9u3bh99++w3r1q3jRXpERERUJnj+Nj2KHoO8efNm7Nu3D/v27cOZM2fg4uKCl156CQsWLMDLL78sd3hEREREJANF9yC7ubmhTZs2aNu2Ldq2bYt69erJHVKR+BcoERGR6eH52/Qougc5OTlZ7hCIiIiIqJxR9EV6r7zyCsLCwgzK7969i1deeUWGiIiIiIhIboruQd63bx9OnTqFY8eOYe3atbCzswMAZGdnY//+/TJHR0RERERyUHQPMgBEREQgKSkJL774IuLj4+UOh4iIiIhkpvgE2dPTE/v370dAQACaNm2Kffv2yR0SERGR4uVpBCIv38Fvx28g8vId5GkUO6cAyUDRQywkSQIAqFQqrF27FtOnT0fHjh0xbtw4mSMjIiJSrp2nExG2LRaJaZnaMk+1NaaE+KNjPU8ZIyOlUPQ0b2ZmZkhKSoKbm5u27Ndff0X//v3x8OFD3iiEiIjoGdt5OhHvhsegYHIi/f+/S/s0Nrkkmedv06PoHuS4uDi4urrqlb3xxhuoXbs2oqOjZYqKiIhImfI0AmHbYg2SYwAQeJQkh22LRXt/D5ibSUZqEZUNRSfI3t7eRsvr1q2LunXrPuNoiIiIlC0qLkVvWEVBAkBiWiai4lLQws/l2QVGiqP4i/SIiIiofEi+V3hyXJp6RKXFBJmIiIjKBTcH6zKtR1RaTJCJiIioXGjm6wxPtTUKG10s4dFsFs18nZ9lWKRATJCJiIioXDA3kzAlxB8ADJLk/OdTQvx5gR49dYq+SC9fbGwsrl69iuzsbL3yLl26yBQRERGRMnWs54mlfRobzIPswXmQ6RlSdIJ85coVdOvWDadOnYIkScifEjr/BiLlbR5kIiIiJehYzxPt/T0QFZeC5HuZcHN4NKyCPcf0rCh6iMWHH34IX19f3Lp1C7a2tjhz5gz+/vtvNGnShLecJiIikpG5mYQWfi7o2rASWvi5MDmmZ0rRPciRkZHYs2cPXF1dYWZmBjMzM7Ru3RqzZs3CyJEjcezYMblDJCIiIqJnTNE9yHl5ebC3twcAVKxYETdv3gTw6AYi58+flzM0IiIiIpKJonuQ69Wrh5MnT6JatWpo3rw55s6dCysrK3z33XeoVq2a3OERERERkQwUnSBPmjQJDx48AABMnz4dr732Gl566SW4uLhg48aNMkdHRERERHKQRP7UDQQASElJgZOTk3Ymi/IkPT0darUaaWlpcHR0lDscIiIiKgaev02PonuQjXF25t15iIiIiJRM0QnygwcPMHv2bOzevRvJycnQaDR6y69cuSJTZEREREQkF0UnyEOGDMH+/fvRt29feHp6lsthFURERET0bCk6Qf7jjz+wY8cOtGrVSu5QiIiIiKicUPQ8yE5OThxzTERERER6FJ0gf/755/jss8+QkZEhdyhEREREVE4oeojFvHnzcPnyZbi7u8PHxweWlpZ6y2NiYmSKjIiIiIjkougE+fXXX5c7BCIiIiIqZ3ijEBPCicaJiIhMD8/fpkfRY5CJiIiIiApigkxEREREpIMJMhERERGRDibIREREREQ6FD2LBRGVTp5GICouBcn3MuHmYI1mvs4wN+Ot2omI6PmguAR59OjRxa47f/78Ytf18fFBQkKCQfmIESOwcOFCTJo0Cb///juuXLkCtVqNdu3aYfbs2fDy8ir2NojKg52nExG2LRaJaZnaMk+1NaaE+KNjPU8ZIyMiIiobikuQjx07pvf833//RV5eHmrVqgUAuHDhAszNzfHCCy+UaL1Hjx5FXl6e9vnp06fRvn179OjRAxkZGYiJicHkyZPRoEED3L17F6NGjUKXLl0QHR395I0iekZ2nk7Eu+ExKDg3ZFJaJt4Nj8HSPo2ZJBMRkclTXIK8d+9e7f/nz58PBwcHrF69Gk5OTgCAu3fvYuDAgXjppZdKtF5XV1e957Nnz4afnx8CAwMhSRJ27dqlt3zRokVo1qwZrl69iqpVq5ayNUTPTp5GIGxbrEFyDAACgAQgbFss2vt7cLgFERGZNEVfpDdv3jzMmjVLmxwDgJOTE6ZPn4558+aVer3Z2dkIDw/HoEGDIEnGE4W0tDRIkoQKFSoUup6srCykp6frPYjkEhWXojesoiABIDEtE1FxKc8uKCIioqdA0Qlyeno6bt26ZVCenJyMe/fulXq9W7ZsQWpqKgYMGGB0eWZmJsaPH4/Q0NAi76gza9YsqNVq7aNKlSqljonoSSXfKzw5Lk09IiKi8krRCXK3bt0wcOBA/PLLL7h+/TquX7+OX375BYMHD0b37t1Lvd4VK1agU6dORi/Ay8nJQc+ePaHRaLBkyZIi1zNhwgSkpaVpH9euXSt1TERPys3BukzrERERlVeKG4Osa9myZfj444/Rp08f5OTkAAAsLCwwePBgfPHFF6VaZ0JCAiIiIrBp0yaDZTk5OXjrrbcQFxeHPXv2PPZ+7CqVCiqVqlRxEJW1Zr7O8FRbIykt0+g4ZAmAh/rRlG9ERESmTNE9yLa2tliyZAnu3LmDY8eOISYmBikpKViyZAns7OxKtc6VK1fCzc0NwcHBeuX5yfHFixcREREBFxeXsmgC0TNjbiZhSog/gEfJsK7851NC/HmBHhERmTxFJ8j57OzsEBAQgAYNGpQ6MQYAjUaDlStXon///rCw+F/nfG5uLt58801ER0dj7dq1yMvLQ1JSEpKSkpCdnV0WTSB6JjrW88TSPo3hodYfRuGhtuYUb0RE9NyQhBDGfi19bnXv3h2rVq2Co6PjY8cZ29vbo27duhg+fDjUavVj1/3XX38hKCgI58+fR82aNbXl8fHx8PX1NfqavXv3om3btsWKPT09HWq1GmlpaY8dnkH0NPFOekRExcfzt+lR3BhktVqtnXrtcUlvVlYWli1bhkOHDmHr1q2PXXeHDh1g7O8NHx8fo+VEpsrcTEILPw4TIiKi55PiepBLKjY2Fk2bNsWDBw/kDoV/gRIREZkgnr9ND8cgP0atWrVw+PBhucMgIiIiomdEcUMsSjIGedOmTTA3N0eDBg2eUXREREREJDfFJci6Y5AdHR0LvRU0ERERESkTxyCbEI5hIiIiMj08f5seRY9BfuWVV5CammpQnp6ejldeeeXZB0REREREslN0grxv3z6jN+rIzMzEgQMHZIiIiIiIiOSmuDHIAHDy5Ent/2NjY5GUlKR9npeXh507d6JSpUpyhEZEREREMlNkgtywYUNIkgRJkowOpbCxscGiRYtkiIyIiIiI5KbIBDkuLg5CCFSrVg1RUVFwdXXVLrOysoKbmxvMzc1ljJCIiIiI5KLIBNnb2xsAoNFoZI6EiIiIiMobxSXIW7duLXbdLl26PMVIiIiIiKg8UlyC/PrrrxerniRJyMvLe7rBEBEREVG5o7gEmcMqiIiIiKgoip4HWVdmZqbcIRARERFROaDoBDkvLw+ff/45KlWqBHt7e1y5cgUAMHnyZKxYsULm6IiIiIhIDopOkGfMmIFVq1Zh7ty5sLKy0pbXr18fy5cvlzEyIiIiIpKLohPkNWvW4LvvvkPv3r315j0OCAjAuXPnZIyMiIiIiOSi6AT5xo0bqF69ukG5RqNBTk6ODBERERERkdwUnSDXrVsXBw4cMCj/+eef0ahRIxkiIiIiIiK5KW6aN11TpkxB3759cePGDWg0GmzatAnnz5/HmjVrsH37drnDIyIiIiIZKLoHOSQkBBs3bsTvv/8OSZLw2Wef4ezZs9i2bRvat28vd3hEREREJANJCCHkDoKKJz09HWq1GmlpaXB0dJQ7HCIiIioGnr9Nj6J7kKtVq4Y7d+4YlKempqJatWoyREREREREclN0ghwfH4+8vDyD8qysLNy4cUOGiIiIiIhIboq8SG/r1q3a///5559Qq9Xa53l5edi9ezd8fHxkiIyIiIiI5KbIBPn1118HAEiShP79++sts7S0hI+PD+bNmydDZEREREQkN0UmyBqNBgDg6+uLo0ePomLFijJHRERERETlhSIT5HxxcXEGZampqahQocKzD4aIiIiIygVFX6Q3Z84cbNy4Ufu8R48ecHZ2RqVKlXDixAkZIyMiIiIiuSg6Qf72229RpUoVAMCuXbsQERGBnTt3olOnThg7dqzM0RERERGRHBQ9xCIxMVGbIG/fvh1vvfUWOnToAB8fHzRv3lzm6IiIiIhIDoruQXZycsK1a9cAADt37kS7du0AAEIIo/MjExEREdHzT9E9yN27d0doaChq1KiBO3fuoFOnTgCA48ePo3r16jJHR0RERERyUHSCvGDBAvj6+uLq1auYO3cu7O3tATwaejFixAiZoyMiIiIiOSg2Qc7JycHQoUMxefJkVKtWTW/ZqFGj5AmKiIiIiGSn2DHIlpaW2Lx5s9xhEBEREVE5o9gEGQC6deuGLVu2yB0GEREREZUjih1iAQDVq1fH559/jsOHD+OFF16AnZ2d3vKRI0fKFBkRERERyUUSQgi5g5CLr69vocskScKVK1eeYTSPl56eDrVajbS0NDg6OsodDhERERUDz9+mR9E9yHFxcXKHQERERETljKLHIOfLzs7G+fPnkZubK3coRERERCQzRSfIGRkZGDx4MGxtbVG3bl1cvXoVwKOxx7Nnz5Y5OiIiIiKSg6IT5AkTJuDEiRPYt28frK2tteXt2rXDxo0bZYyMiIiIiOSi6DHIW7ZswcaNG/Hiiy9CkiRtub+/Py5fvixjZEREREQkF0X3IN++fRtubm4G5Q8ePNBLmImIiIhIORSdIDdt2hQ7duzQPs9Pir///nu0aNFCrrCIiIiISEaKHmIxa9YsdOzYEbGxscjNzcVXX32FM2fOIDIyEvv375c7PCIiIiKSgaJ7kFu2bIlDhw4hIyMDfn5++Ouvv+Du7o7IyEi88MILcodHRERERDJQ9J30TM3TuhNPnkYgKi4Fyfcy4eZgjWa+zjA34xhsIiKissA76ZkeRQ6xSE9PL1a9kuzEPj4+SEhIMCgfMWIEFi9eDCEEwsLC8N133+Hu3bto3rw5Fi9ejLp16xZ7G0/DztOJCNsWi8S0TG2Zp9oaU0L80bGep4yREREREclDkUMsKlSoACcnp0If+ctL4ujRo0hMTNQ+du3aBQDo0aMHAGDu3LmYP38+vvnmGxw9ehQeHh5o37497t27V+btK66dpxPxbniMXnIMAElpmXg3PAY7TyfKFBkRERGRfBTZg7x3717t/4UQ6Ny5M5YvX45KlSqVep2urq56z2fPng0/Pz8EBgZCCIGFCxdi4sSJ6N69OwBg9erVcHd3x7p16zBs2LBSb7e08jQCYdtiYWx8jQAgAQjbFov2/h4cbkFERESKosgEOTAwUO+5ubk5XnzxRVSrVq1M1p+dnY3w8HCMHj0akiThypUrSEpKQocOHbR1VCoVAgMDcfjw4UIT5KysLGRlZWmfF3doSHFExaUY9BzrEgAS0zIRFZeCFn4uZbZdIiIiovJOkUMsnrYtW7YgNTUVAwYMAAAkJSUBANzd3fXqubu7a5cZM2vWLKjVau2jSpUqZRZj8r3Ck+PS1CMiIiJ6XjBBfgpWrFiBTp06wcvLS6+84N35hBBF3rFvwoQJSEtL0z6uXbtWZjG6OViXaT0iIiKi54Uih1gYU1a3lk5ISEBERAQ2bdqkLfPw8ADwqCfZ0/N/M0MkJycb9CrrUqlUUKlUZRJXQc18neGptkZSWqbRccgSAA/1oynfiIiIiJREkQly/oVy+TIzMzF8+HDY2dnplesmucW1cuVKuLm5ITg4WFvm6+sLDw8P7Nq1C40aNQLwaJzy/v37MWfOnFK04MmZm0mYEuKPd8NjIAF6SXL+nwpTQvx5gR4REREpjiITZLVarfe8T58+ZbJejUaDlStXon///rCw+N9bK0kSRo0ahZkzZ6JGjRqoUaMGZs6cCVtbW4SGhpbJtkujYz1PLO3T2GAeZA/Og0xEREQKpsgEeeXKlU9lvREREbh69SoGDRpksOyTTz7Bw4cPMWLECO2NQv766y84ODg8lViKq2M9T7T39+Cd9IiIiIj+H281bUJ4q0oiIiLTw/O36eEsFkREREREOpggExERERHpYIJMRERERKSDCTIRERERkQ4myEREREREOpggExERERHpYIJMRERERKSDCTIRERERkQ4myEREREREOpggExERERHpYIJMRERERKSDCTIRERERkQ4myEREREREOpggExERERHpYIJMRERERKSDCTIRERERkQ4myEREREREOpggExERERHpYIJMRERERKTDQu4AiIiIiArK0whExaUg+V4m3Bys0czXGeZmktxhkUIwQSYiIqJyZefpRIRti0ViWqa2zFNtjSkh/uhYz1PGyEgpOMSCiIiIyo2dpxPxbniMXnIMAElpmXg3PAY7TyfKFBkpCRNkIiIiKhfyNAJh22IhjCzLLwvbFos8jbEaRGWHCTIRERGVC1FxKQY9x7oEgMS0TETFpTy7oEiRmCATERFRuZB8r/DkuDT1iEqLCTIRERGVC24O1mVaj6i0mCATERFRudDM1xmeamsUNpmbhEezWTTzdX6WYZECMUEmIiKicsHcTMKUEH8AMEiS859PCfHnfMj01DFBJiIionKjYz1PLO3TGB5q/WEUHmprLO3TmPMg0zPBG4UQERFRudKxnifa+3vwTnokGybIREREVO6Ym0lo4ecidxikUBxiQURERESkgwkyEREREZEOJshERERERDqYIBMRERER6WCCTERERESkgwkyEREREZEOJshERERERDqYIBMRERER6WCCTERERESkg3fSMyFCCABAenq6zJEQERFRceWft/PP41T+MUE2Iffu3QMAVKlSReZIiIiIqKTu3bsHtVotdxhUDJLgnzMmQ6PR4ObNm3BwcIAkSXKH80TS09NRpUoVXLt2DY6OjnKHU+ae9/YBz38b2T7T97y38XlvH/D8tFEIgXv37sHLywtmZhzdagrYg2xCzMzMULlyZbnDKFOOjo4mfdB7nOe9fcDz30a2z/Q972183tsHPB9tZM+xaeGfMUREREREOpggExERERHpYIJMslCpVJgyZQpUKpXcoTwVz3v7gOe/jWyf6Xve2/i8tw9QRhupfOJFekREREREOtiDTERERESkgwkyEREREZEOJshERERERDqYIBMRERER6WCCTE/VjRs30KdPH7i4uMDW1hYNGzbEv//+q1fn7Nmz6NKlC9RqNRwcHPDiiy/i6tWrMkVcco9r4/379/H++++jcuXKsLGxQZ06dbB06VIZIy4+Hx8fSJJk8HjvvfcAPLo71NSpU+Hl5QUbGxu0bdsWZ86ckTnq4iuqfTk5ORg3bhzq168POzs7eHl5oV+/frh586bcYZfI4z5DXcOGDYMkSVi4cOGzD7SUitM+Uz7GPK59pnx8yZebm4tJkybB19cXNjY2qFatGqZNmwaNRqOtY+rHGjJBgugpSUlJEd7e3mLAgAHin3/+EXFxcSIiIkJcunRJW+fSpUvC2dlZjB07VsTExIjLly+L7du3i1u3bskYefEVp41DhgwRfn5+Yu/evSIuLk58++23wtzcXGzZskXGyIsnOTlZJCYmah+7du0SAMTevXuFEELMnj1bODg4iF9//VWcOnVKvP3228LT01Okp6fLG3gxFdW+1NRU0a5dO7Fx40Zx7tw5ERkZKZo3by5eeOEFucMukcd9hvk2b94sGjRoILy8vMSCBQtkibU0Htc+Uz/GPK59pnx8yTd9+nTh4uIitm/fLuLi4sTPP/8s7O3txcKFC7V1TP1YQ6aHCTI9NePGjROtW7cuss7bb78t+vTp84wiKnvFaWPdunXFtGnT9MoaN24sJk2a9DRDeyo+/PBD4efnJzQajdBoNMLDw0PMnj1buzwzM1Oo1WqxbNkyGaMsPd32GRMVFSUAiISEhGccWdkx1sbr16+LSpUqidOnTwtvb2+TSpALKtg+Uz/GFFSwfc/D8SU4OFgMGjRIr6x79+7az+15PNZQ+cchFvTUbN26FU2aNEGPHj3g5uaGRo0a4fvvv9cu12g02LFjB2rWrImgoCC4ubmhefPm2LJli3xBl9Dj2ggArVu3xtatW3Hjxg0IIbB3715cuHABQUFBMkVdOtnZ2QgPD8egQYMgSRLi4uKQlJSEDh06aOuoVCoEBgbi8OHDMkZaOgXbZ0xaWhokSUKFChWebXBlxFgbNRoN+vbti7Fjx6Ju3boyR/hkCrbveTjG6DL2+T0Px5fWrVtj9+7duHDhAgDgxIkTOHjwIDp37gwAz92xhkyE3Bk6Pb9UKpVQqVRiwoQJIiYmRixbtkxYW1uL1atXCyGESExMFACEra2tmD9/vjh27JiYNWuWkCRJ7Nu3T+boi+dxbRRCiKysLNGvXz8BQFhYWAgrKyuxZs0aGaMunY0bNwpzc3Nx48YNIYQQhw4dEgC0z/O98847okOHDnKE+EQKtq+ghw8fihdeeEH07t37GUdWdoy1cebMmaJ9+/baHklT7kEu2L7n4Rijy9jn9zwcXzQajRg/fryQJElYWFgISZLEzJkztcuft2MNmQYmyPTUWFpaihYtWuiVffDBB+LFF18UQghx48YNAUD06tVLr05ISIjo2bPnM4vzSTyujUII8cUXX4iaNWuKrVu3ihMnTohFixYJe3t7sWvXrmcd7hPp0KGDeO2117TP809aN2/e1Ks3ZMgQERQU9KzDe2IF26crOztbdO3aVTRq1EikpaU948jKTsE2RkdHC3d3d73Ew5QT5ILtex6OMbqM7aPPw/Fl/fr1onLlymL9+vXi5MmTYs2aNcLZ2VmsWrVKCPH8HWvINFjI1XNNzz9PT0/4+/vrldWpUwe//vorAKBixYqwsLAwWufgwYPPLM4n8bg2Pnz4EJ9++ik2b96M4OBgAEBAQACOHz+OL7/8Eu3atXvmMZdGQkICIiIisGnTJm2Zh4cHACApKQmenp7a8uTkZLi7uz/zGJ+Esfbly8nJwVtvvYW4uDjs2bMHjo6OMkT45Iy18cCBA0hOTkbVqlW1ZXl5eRgzZgwWLlyI+Ph4GSItHWPtex6OMfmMte95Ob6MHTsW48ePR8+ePQEA9evXR0JCAmbNmoX+/fs/V8caMh0cg0xPTatWrXD+/Hm9sgsXLsDb2xsAYGVlhaZNmxZZp7x7XBtzcnKQk5MDMzP9r5q5ubneFEbl3cqVK+Hm5qY9CQOAr68vPDw8sGvXLm1ZdnY29u/fj5YtW8oRZqkZax/wv+T44sWLiIiIgIuLi0wRPjljbezbty9OnjyJ48ePax9eXl4YO3Ys/vzzTxmjLTlj7XsejjH5jLXveTm+ZGRkFNmG5+lYQyZE7i5sen5FRUUJCwsLMWPGDHHx4kWxdu1aYWtrK8LDw7V1Nm3aJCwtLcV3330nLl68KBYtWiTMzc3FgQMHZIy8+IrTxsDAQFG3bl2xd+9eceXKFbFy5UphbW0tlixZImPkxZeXlyeqVq0qxo0bZ7Bs9uzZQq1Wi02bNolTp06JXr16mdzUS4W1LycnR3Tp0kVUrlxZHD9+XG+qraysLJmiLZ2iPsOCTHGIRVHtM/VjjBBFt8/Ujy9CCNG/f39RqVIl7TRvmzZtEhUrVhSffPKJts7zcKwh08IEmZ6qbdu2iXr16gmVSiVq164tvvvuO4M6K1asENWrVxfW1taiQYMGJjV/pxCPb2NiYqIYMGCA8PLyEtbW1qJWrVpi3rx5hU4lVt78+eefAoA4f/68wTKNRiOmTJkiPDw8hEqlEm3atBGnTp2SIcrSK6x9cXFxAoDRR8E5hMu7oj7DgkwxQX5c+0z9GFNU+0z9+CKEEOnp6eLDDz8UVatWFdbW1qJatWpi4sSJen+IPg/HGjItkhBCyNR5TURERERU7nAMMhERERGRDibIREREREQ6mCATEREREelggkxEREREpIMJMhERERGRDibIREREREQ6mCATEREREelggkxEJkuSJGzZskXuMAAAU6dORcOGDQt9bsyAAQPw+uuvP3bdffv2xcyZM7XPfXx8sHDhwtIFWg5s374djRo1MqnbIRORsjBBJqJyKTk5GcOGDUPVqlWhUqng4eGBoKAgREZGyh2a0cT8448/xu7duwt9XlonT57Ejh078MEHH2jLjh49iqFDhz7xuuXy2muvQZIkrFu3Tu5QiIiMspA7ACIiY9544w3k5ORg9erVqFatGm7duoXdu3cjJSVF7tCMsre3h729faHPS+ubb75Bjx494ODgoC1zdXV94vWWRk5ODiwtLctkXQMHDsSiRYvQp0+fMlkfEVFZYg8yEZU7qampOHjwIObMmYOXX34Z3t7eaNasGSZMmIDg4OBCXzdu3DjUrFkTtra2qFatGiZPnoycnBzt8suXL6Nr165wd3eHvb09mjZtioiICL11+Pj44PPPP0doaCjs7e3h5eWFRYsW6S0HgG7dukGSJO3zxw2xyMvLw+jRo1GhQgW4uLjgk08+gRCiyPdBo9Hg559/RpcuXQxi1B1iIUkSli9fjm7dusHW1hY1atTA1q1bi1y3sV7wChUqYNWqVQCA+Ph4SJKEn376CW3btoW1tTXCw8MBACtXrkSdOnVgbW2N2rVrY8mSJdp15L9u06ZNePnll2Fra4sGDRoY9Px36dIFUVFRuHLlSpFxEhHJgQkyEZU7+b2vW7ZsQVZWVrFf5+DggFWrViE2NhZfffUVvv/+eyxYsEC7/P79++jcuTMiIiJw7NgxBAUFISQkBFevXtVbzxdffIGAgADExMRgwoQJ+Oijj7Br1y4Aj4Y3AI+SxMTERO3zx5k3bx5++OEHrFixAgcPHkRKSgo2b95c5GtOnjyJ1NRUNGnS5LHrDwsLw1tvvYWTJ0+ic+fO6N27d5n0to8bNw4jR47E2bNnERQUhO+//x4TJ07EjBkzcPbsWcycOROTJ0/G6tWr9V43ceJEfPzxxzh+/Dhq1qyJXr16ITc3V7vc29sbbm5uOHDgwBPHSERU5gQRUTn0yy+/CCcnJ2FtbS1atmwpJkyYIE6cOKFXB4DYvHlzoeuYO3eueOGFF4rcjr+/v1i0aJH2ube3t+jYsaNenbffflt06tSpyO1OmTJFNGjQoNDnnp6eYvbs2drnOTk5onLlyqJr166FxrZ582Zhbm4uNBqNXrm3t7dYsGCBXjyTJk3SPr9//76QJEn88ccfha7bWBvUarVYuXKlEEKIuLg4AUAsXLhQr06VKlXEunXr9Mo+//xz0aJFC73XLV++XLv8zJkzAoA4e/as3usaNWokpk6dWmiMRERyYQ8yEZVLb7zxBm7evImtW7ciKCgI+/btQ+PGjbVDAIz55Zdf0Lp1a3h4eMDe3h6TJ0/W6x1+8OABPvnkE/j7+6NChQqwt7fHuXPnDHqQW7RoYfD87NmzpW5LWloaEhMT9dZrYWHx2J7hhw8fQqVSQZKkx24jICBA+387Ozs4ODggOTm51DHn043x9u3buHbtGgYPHqzt5be3t8f06dNx+fLlQuPx9PQEAIN4bGxskJGR8cQxEhGVNV6kR0TllrW1Ndq3b4/27dvjs88+w5AhQzBlyhQMGDDAoO6RI0fQs2dPhIWFISgoCGq1Ghs2bMC8efO0dcaOHYs///wTX375JapXrw4bGxu8+eabyM7OfmwsxUlSy1rFihWRkZGB7OxsWFlZFVm34MVzkiQVOY2aJEkGY6B1x2vns7Oz0/4/f33ff/89mjdvrlfP3Ny80Hjy37uC8aSkpMh2wSERUVGYIBORyfD39y903uNDhw7B29sbEydO1JYlJCTo1Tlw4AAGDBiAbt26AXg0Jjk+Pt5gXUeOHDF4Xrt2be1zS0tL5OXlFTtutVoNT09PHDlyBG3atAEA5Obm4t9//0Xjxo0LfV3+RX6xsbGPnVO5pFxdXZGYmKh9fvHixcf25rq7u6NSpUq4cuUKevfu/UTbz8zMxOXLl9GoUaMnWg8R0dPABJmIyp07d+6gR48eGDRoEAICAuDg4IDo6GjMnTsXXbt2Nfqa6tWr4+rVq9iwYQOaNm2KHTt2GFwEV716dWzatAkhISGQJAmTJ0822st66NAhzJ07F6+//jp27dqFn3/+GTt27NAu9/Hxwe7du9GqVSuoVCo4OTk9tk0ffvghZs+ejRo1aqBOnTqYP38+UlNTi3yNq6srGjdujIMHD5Z5gvzKK6/gm2++wYsvvgiNRoNx48YVawq3qVOnYuTIkXB0dESnTp2QlZWF6Oho3L17F6NHjy729o8cOQKVSmUwnIWIqDzgGGQiKnfs7e3RvHlzLFiwAG3atEG9evUwefJkvPPOO/jmm2+MvqZr16746KOP8P7776Nhw4Y4fPgwJk+erFdnwYIFcHJyQsuWLRESEoKgoCCjPbhjxozBv//+i0aNGuHzzz/HvHnzEBQUpF0+b9487Nq1C1WqVCl2D+iYMWPQr18/DBgwAC1atICDg4O2J7soQ4cOxdq1a4u1jZKYN28eqlSpgjZt2iA0NBQff/wxbG1tH/u6IUOGYPny5Vi1ahXq16+PwMBArFq1Cr6+viXa/vr169G7d+9ibZOI6FmTRMFBaERECubj44NRo0Zh1KhRT7SeCRMm4MCBAzh48OATrSczMxO1atXChg0bnpve1tu3b6N27dqIjo4ucWJNRPQssAeZiKgMCSFw+fJl7N69G3Xr1n3i9VlbW2PNmjX477//yiC68iEuLg5LlixhckxE5RbHIBMRlaG0tDT4+/ujadOm+PTTT8tknYGBgWWynvKiWbNmaNasmdxhEBEVikMsiIiIiIh0cIgFEREREZEOJshERERERDqYIBMRERER6WCCTERERESkgwkyEREREZEOJshERERERDqYIBMRERER6WCCTERERESkgwkyEREREZGO/wOs+BkGnTGg+AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)  # Zet de seed\n",
    "X = [4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0]\n",
    "            # + np.random.normal(loc=0, scale=40, size=len(Y))# oefeningstijd (min)\n",
    "Y = [66, 61, 63, 62, 65, 64, 57, 59, 60]\n",
    "\n",
    "X = [80, 81, 80, 70, 72, 69, 65, 74, 80]  # F-16\n",
    "Y = [80, 74, 73, 72, 78, 75, 70, 74, 69]  # F-35\n",
    "\n",
    "X_pred = 6.75\n",
    "labels = {\n",
    "    \"X\": \"Slaaptijd (in uren)\",\n",
    "    \"Y\": \"Hersteltijd na zware inspanning (in uren)\"\n",
    "}\n",
    "\n",
    "# Generate LaTeX table for the question itself (horizontal)\n",
    "latex_table = generate_latex_table(X, Y, labels)\n",
    "print(latex_table)\n",
    "\n",
    "# Plot X and Y in a scatter plot\n",
    "plot_linear_regression(X, Y, labels, x_0 = X_pred, \\\n",
    "                           plot_least_squares=False, plot_regression_line=False, \\\n",
    "                           plot_point_estimate=False, plot_prediction_interval=False,\\\n",
    "                           filename=FIGURE_PATH + \"test_scatterplot.png\")\n",
    "\n",
    "# Generate LaTeX table for computing the regression line and the correlation coefficient\n",
    "regression_table = generate_latex_table_regression(X, Y)\n",
    "print(regression_table)\n",
    "\n",
    "regression_coefficients, a, b = regression_coefficients_latex(X, Y)\n",
    "print(regression_coefficients)\n",
    "\n",
    "Y_pred = a + b * X_pred\n",
    "print(f\"Voorspelde waarde voor $Y$ bij $X = {X_pred}$ is gelijk aan {Y_pred}\")\n",
    "\n",
    "pearson = pearson_correlation_latex(X, Y)\n",
    "print(pearson)\n",
    "\n",
    "spearman = spearman_correlation_latex(X, Y)\n",
    "print(spearman)\n",
    "\n",
    "# Confidence interval for the mean given x0\n",
    "x0 = 6.75\n",
    "alpha = 0.1\n",
    "\n",
    "confidence_interval, y_pred, ci = regression_confidence_interval(X, Y, a, b, x0, confidence=1-alpha)\n",
    "print(confidence_interval)\n",
    "\n",
    "prediction_interval, y_pred, pi = regression_prediction_interval(X, Y, a, b, x0, confidence=1-alpha)\n",
    "print(prediction_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bcc640-cef7-4920-9f4c-f8bca7ed3edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee86d8-d6a9-4113-a430-a30035625420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
