{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c45f524b-f776-4e3e-9106-1c7188b4b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222fcfa-f39d-4d56-98a2-ed37f9e723bc",
   "metadata": {},
   "source": [
    "# Correlatie en Regressie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "938669e2-7730-4633-b481-24001f17e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(X, Y, labels):\n",
    "    # Start building the LaTeX table\n",
    "    xlabel, ylabel = labels.values()\n",
    "    n = len(X)\n",
    "    alignment_chars = \"{c|\" + \"c\" * n + \"}\"\n",
    "    latex_code = f\"\"\"\n",
    "        \\\\begin{{center}}\n",
    "            \\\\begin{{tabular}}{alignment_chars}\n",
    "                \\\\toprule\n",
    "                    \\\\textbf{{{xlabel}}} {\" \".join([f\"& ${x}$\" for x in X])} \\\\\\\\\n",
    "                    \\\\textbf{{{ylabel}}} {\" \".join([f\"& ${y}$\" for y in Y])} \\\\\\\\\n",
    "                \\\\bottomrule\n",
    "            \\\\end{{tabular}}\n",
    "        \\\\end{{center}}\n",
    "    \"\"\"\n",
    "    \n",
    "    return latex_code\n",
    "\n",
    "def generate_latex_table_regression(X, Y):\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "       \n",
    "    # Start building the LaTeX table\n",
    "    latex_code = \"\"\"\n",
    "        \\\\begin{center}\n",
    "            \\\\begin{tabular}{ccccc}\n",
    "                \\\\toprule\n",
    "                    $x$ & $y$ & $xy$ & $x^2$ & $y^2$ \\\\\\\\\n",
    "                \\\\midrule\n",
    "    \"\"\"\n",
    "    \n",
    "    # Populate table rows\n",
    "    for x, y, xy, x2, y2 in zip(X, Y, X * Y, X ** 2, Y ** 2):\n",
    "        x, y, xy, x2, y2 = map(lambda p: pretty_print(p), (x, y, xy, x2, y2))\n",
    "        latex_code += f\"\\t\\t${x}$ & ${y}$ & ${xy}$ & ${x2}$ & ${y2}$ \\\\\\\\\\n\"\n",
    "    \n",
    "    # Add final row with averages\n",
    "    # Compute averages\n",
    "    avg_X, avg_Y, avg_XY, avg_X2, avg_Y2 = map(lambda x: pretty_print(np.mean(x)), [X, Y, X * Y, X ** 2, Y ** 2])\n",
    "\n",
    "    latex_code += f\"\"\"\n",
    "                \\\\midrule\n",
    "                    $\\\\overline{{x}} = {avg_X}$ & $\\\\overline{{y}} = {avg_Y}$ & $\\\\overline{{xy}} = {avg_XY}$ & $\\\\overline{{x^2}} = {avg_X2}$ & $\\\\overline{{y^2}} = {avg_Y2}$ \\\\\\\\\n",
    "                \\\\bottomrule\n",
    "            \\\\end{{tabular}}\n",
    "        \\\\end{{center}}\n",
    "    \"\"\"    \n",
    "    return latex_code\n",
    "\n",
    "def regression_coefficients_latex(X, Y):  \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    avg_X = np.mean(X)\n",
    "    avg_Y = np.mean(Y)\n",
    "    avg_XY = np.mean(X * Y)\n",
    "    avg_X_squared = np.mean(X ** 2)\n",
    "    \n",
    "    # Beta_1 (slope)\n",
    "    numerator = avg_XY - avg_X * avg_Y\n",
    "    denominator = avg_X_squared - avg_X**2\n",
    "    beta_1 = numerator / denominator\n",
    "    \n",
    "    # Beta_0 (intercept)\n",
    "    beta_0 = avg_Y - beta_1 * avg_X\n",
    "    \n",
    "    # LaTeX output\n",
    "    latex_code = f\"\"\"\n",
    "        \\\\begin{{align*}}\n",
    "            b &= \\\\frac{{\\\\overline{{xy}} - \\\\overline{{x}} \\\\cdot \\\\overline{{y}}}}{{\\\\overline{{x^2}} - (\\\\overline{{x}})^2}} \\\\\\\\\n",
    "              &= \\\\frac{{{pretty_print(avg_XY)} - {pretty_print(avg_X)} \\\\cdot {pretty_print(avg_Y)}}}{{{pretty_print(avg_X_squared)} - ({pretty_print(avg_X)})^2}} \\\\\\\\\n",
    "              &= \\\\frac{{{pretty_print(numerator)}}}{{{pretty_print(denominator)}}} \\\\approx {pretty_print(beta_1)} \\\\\\\\\n",
    "            a &= \\\\overline{{y}} - b \\\\cdot \\\\overline{{x}} \\\\\\\\\n",
    "              &= {pretty_print(avg_Y)} - {pretty_print(beta_1)} \\\\cdot {pretty_print(avg_X)} \\\\\\\\\n",
    "              &\\\\approx {pretty_print(beta_0)}.\n",
    "        \\\\end{{align*}}\n",
    "\n",
    "        De formule van de regressielijn behorende bij deze steekproef is dus gelijk aan $Y = {pretty_print(beta_0)}{beta_1:+.4f}X$.\n",
    "    \"\"\"\n",
    "    return latex_code, beta_0, beta_1\n",
    "\n",
    "\n",
    "def pearson_correlation_latex(X, Y):\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    # Compute necessary statistical values\n",
    "    avg_X, avg_Y, avg_XY, avg_X_squared, avg_Y_squared = np.mean(X), np.mean(Y), np.mean(X*Y), np.mean(X ** 2), np.mean(Y ** 2)\n",
    "\n",
    "    \n",
    "    # Compute Pearson correlation coefficient\n",
    "    numerator = avg_XY - (avg_X * avg_Y)\n",
    "    denominator = np.sqrt((avg_X**2 - avg_X_squared) * (avg_Y**2 - avg_Y_squared))\n",
    "    r = numerator / denominator\n",
    "    \n",
    "    # Generate LaTeX output\n",
    "    latex_code = f\"\"\"\n",
    "        \\\\begin{{align*}}\n",
    "            r(x,y)  &= \\\\frac{{ \\\\overline{{x \\\\cdot y}} - \\\\overline{{x}} \\\\cdot \\\\overline{{y}} }}{{ \\\\sqrt{{ (\\\\overline{{x}}^2 - \\\\overline{{x^2}}) \\\\cdot (\\\\overline{{y}}^2 - \\\\overline{{y^2}}) }} }}\\\\\\\\\n",
    "                    &= \\\\frac{{ {pretty_print(avg_XY)} - {pretty_print(avg_X)} \\\\cdot {pretty_print(avg_Y)} }}{{ \\\\sqrt{{ ({pretty_print(avg_X)}^2 - {pretty_print(avg_X_squared)}) \\\\cdot ({pretty_print(avg_Y)}^{2} - {pretty_print(avg_Y_squared)}) }} }} \\\\\\\\\n",
    "                    &= \\\\frac{{{pretty_print(numerator)}}}{{{pretty_print(denominator)}}} \\\\\\\\\n",
    "                    &\\\\approx {pretty_print(r)}.\n",
    "        \\\\end{{align*}}\n",
    "    \"\"\"\n",
    "    return latex_code\n",
    "\n",
    "def spearman_correlation_latex(X, Y):\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    if len(X) != len(Y):\n",
    "        raise ValueError(\"Beide lijsten moeten dezelfde lengte hebben.\")\n",
    "    \n",
    "    # Rangschik de gegevens\n",
    "    ranks_X, ranks_Y = rankdata(X), rankdata(Y)\n",
    "    print(ranks_X, ranks_Y)\n",
    "    \n",
    "    # Bereken de verschillen in rang\n",
    "    d = ranks_X - ranks_Y\n",
    "    d_squared = d ** 2\n",
    "    sum_d_squared = sum(d_squared)\n",
    "    n = len(X)\n",
    "    alignment_chars = \"c\" + \"c\" * n\n",
    "    \n",
    "    # Spearman's rho\n",
    "    numerator = 6 * np.sum(d_squared)\n",
    "    denominator = n * (n**2 - 1)\n",
    "    rho = 1 - (numerator / denominator)\n",
    "    \n",
    "    # Genereer LaTeX-uitvoer\n",
    "    latex_code = f\"\"\"\n",
    "        De eerste stap bij het berekenen van Spearman's correlatieco\\\\\"effici\\\\\"ent is het bepalen van de rankings van de uitkomsten voor $X$ en $Y$:\n",
    "        \\\\begin{{center}}\n",
    "            \\\\begin{{tabular}}{{{alignment_chars}}}\n",
    "                \\\\toprule\n",
    "                    {{\\\\bfseries Rangnummers $X$-waarden}} {\" \".join([f\"& ${i}$\" for i in ranks_X])} \\\\\\\\\n",
    "                    {{\\\\bfseries Rangnummers $Y$-waarden}} {\" \".join([f\"& ${i}$\" for i in ranks_Y])} \\\\\\\\\n",
    "                \\\\midrule\n",
    "                    {{\\\\bfseries Verschillen $d_i$}} {\" \".join([f\"& ${diff}$\" for diff in d])} \\\\\\\\\n",
    "                    {{\\\\bfseries Kwadratische verschillen $d_i^2$}} {\" \".join([f\"& ${diff2}$\" for diff2 in d_squared])} \\\\\\\\\n",
    "                \\\\bottomrule\n",
    "            \\\\end{{tabular}}\n",
    "        \\\\end{{center}}\n",
    "\n",
    "        De som van de kwadratische rangnummerverschillen is gelijk aan $\\\\sum_i d_i^2 = {sum_d_squared}$.\n",
    "        Aangezien de steekproefgrootte gelijk is aan $n = {n}$, is de rangcorrelatieco\\\\\"effici\\\\\"ent van Spearman gelijk aan\n",
    "        \\\\begin{{align*}}\n",
    "            r_s &= 1 - \\\\frac{{ 6 \\\\cdot \\\\sum_i d_i^2 }}{{ n^3 - n }}  \\\\\\\\\n",
    "                &= 1 - \\\\frac{{ 6 \\\\cdot {sum_d_squared} }}{{ {n}^3 - {n} }}  \\\\\\\\\n",
    "                &\\\\approx {pretty_print(rho)}.\n",
    "        \\\\end{{align*}}\n",
    "    \"\"\"\n",
    "    \n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258f0156-721d-44d1-9c94-9e571b95756d",
   "metadata": {},
   "source": [
    "## Betrouwbaarheidsinterval voor $E[Y]$ en voorspellingsinterval voor $Y$ gegeven $X = x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5299c5f-9583-4110-ad82-9630857900e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_confidence_interval(X, Y, beta_0, beta_1, x0, confidence=0.95):\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    n = len(X)\n",
    "    mean_X = np.mean(X)\n",
    "    mean_Y = np.mean(Y)\n",
    "    mean_X2 = np.mean(X ** 2)\n",
    "    mean_XY = np.mean(X * Y)\n",
    "    mean_Y2 = np.mean(Y ** 2)\n",
    "    confidence_percentage = int(100 * confidence)\n",
    "    \n",
    "    # 1. Compute the error terms and estimate the standard deviation of the error terms\n",
    "    error_terms = Y - (beta_0 + beta_1 * X)\n",
    "    sample_std_error = np.sqrt( np.sum( error_terms ** 2) / (n - 2) ) \n",
    "\n",
    "    # 2. Use the estimate to estimate the standard deviation of the mean Y given x\n",
    "    sample_std_mean = sample_std_error * np.sqrt( 1 / n * (1 + ((x0 - mean_X) ** 2 / (mean_X2 - mean_X ** 2))) )\n",
    "\n",
    "    y_pred = beta_0 + beta_1 * x0   \n",
    "    t_crit = t.ppf((1 + confidence) / 2, df=n - 2)\n",
    "    margin_error = t_crit * sample_std_mean\n",
    "\n",
    "    # Generate LaTeX output\n",
    "    latex_code = f\"\"\"\n",
    "        De eerste stap is om de puntschatting voor $Y$ te bepalen aan de hand van de regressielijn $Y = {pretty_print(beta_0)}{beta_1:+.4f}X$ door $X = {x0}$ in te vullen.\n",
    "        Dit geeft ons een puntschatting van $y_0 = {pretty_print(beta_0)} {beta_1:+.4f} \\\\cdot {x0} \\\\approx {pretty_print(y_pred)}$.\n",
    "        Daarnaast kunnen we de standaardafwijking $\\\\sigma$ van de storingsterm $\\\\varepsilon$ schatten:\n",
    "        \\\\begin{{align*}}\n",
    "            s_{{\\\\varepsilon}} &= \\\\sqrt{{ \\\\frac{{n}}{{n-2}} \\\\cdot \\\\left( \\\\overline{{y^2}} - a \\\\cdot \\\\overline{{y}} - b \\\\cdot \\\\overline{{xy}} \\\\right) }} \\\\\\\\ \n",
    "                               &= \\\\sqrt{{ \\\\frac{{{n}}}{{{n-2}}} \\\\cdot \\\\left( {pretty_print(mean_Y2)} - {pretty_print(beta_0)} \\\\cdot {pretty_print(mean_Y)} - {pretty_print(beta_1)} \\\\cdot {pretty_print(mean_XY)} \\\\right) }} \\\\\\\\ \n",
    "                               &\\\\approx {pretty_print(sample_std_error)}.\n",
    "        \\\\end{{align*}}\n",
    "\n",
    "        Vervolgens kunnen we een puntschatting berekenen van de standaardafwijking van de verwachtingswaarde van $Y$ voor gegeven $X = x_0$:\n",
    "        \\\\begin{{align*}}\n",
    "        s_{{\\\\mu}}  &= s_{{\\\\varepsilon}} \\\\cdot \\\\sqrt{{ \\\\frac{{1}}{{n}} \\\\cdot \\\\left( 1 + \\\\frac{{(x_0 - \\\\overline{{x}})^2}}{{\\\\overline{{x^2}} - \\\\overline{{x}}^2}} \\\\right) }} \\\\\\\\\n",
    "                    &= {sample_std_error} \\\\cdot \\\\sqrt{{ \\\\frac{{1}}{{{n}}} \\\\cdot \\\\left( 1 + \\\\frac{{({pretty_print(x0)} - {pretty_print(mean_X)})^2}}{{{pretty_print(mean_X2)} - {pretty_print(mean_X)}^2}} \\\\right) }} \\\\\\\\\n",
    "                    &\\\\approx {pretty_print(sample_std_mean)}.   \n",
    "        \\\\end{{align*}}\n",
    "\n",
    "        Omdat we de standaardafwijkingen geschat hebben en de storingstermen normaal verdeeld zijn, moeten we werken met de $t$-verdeling met $df = n - 2 = {n-2}$ vrijheidsgraden.\n",
    "        De $t$-waarde die hoort bij een betrouwbaarheidsniveau $\\\\alpha = {1-confidence}$ is gelijk aan\n",
    "        \\\\[\n",
    "            t = \\\\invt(\\\\text{{opp}} = 1 - \\\\alpha / 2; \\\\text{{df}} = n - 2) = \\\\invt(\\\\text{{opp}} = {1-alpha/2}; \\\\text{{df}} = {n-2}) \\\\approx {pretty_print(t_crit)}.\n",
    "        \\\\]\n",
    "        Het ${int(100 * confidence)}\\\\%$-betrouwbaarheidsinterval voor de gemiddelde $Y$ voor gegeven $X = x_0$ kan dus worden beschreven door\n",
    "        \\\\begin{{align*}}\n",
    "            &[y_0 - t \\\\cdot s_{{\\\\mu}}; y_0 - t \\\\cdot s_{{\\\\mu}}] \\\\\\\\\n",
    "            &= [{pretty_print(y_pred)} - {pretty_print(t_crit)} \\\\cdot {pretty_print(sample_std_mean)}; {pretty_print(y_pred)} + {pretty_print(t_crit)} \\\\cdot {pretty_print(sample_std_mean)}] \\\\\\\\\n",
    "            &\\\\approx [{pretty_print(y_pred - margin_error)}; {pretty_print(y_pred + margin_error)}].\n",
    "        \\\\end{{align*}}\n",
    "        \n",
    "        Met \\\\SI{{{confidence_percentage}}}{{\\\\percent}} betrouwbaarheid ligt het gemiddelde van $Y$ voor gegeven $X = {x0}$ tussen ${pretty_print(y_pred - margin_error)}$ en ${pretty_print(y_pred + margin_error)}$.       \n",
    "    \"\"\"\n",
    "    ci = (y_pred - margin_error, y_pred + margin_error)\n",
    "    return latex_code, y_pred, ci\n",
    "\n",
    "def regression_prediction_interval(X, Y, beta_0, beta_1, x0, confidence=0.95):\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    n = len(X)\n",
    "    mean_X = np.mean(X)\n",
    "    mean_Y = np.mean(Y)\n",
    "    mean_X2 = np.mean(X ** 2)\n",
    "    mean_XY = np.mean(X * Y)\n",
    "    mean_Y2 = np.mean(Y ** 2)\n",
    "    confidence_percentage = int(100 * confidence)\n",
    "\n",
    "    error_terms = Y - (beta_0 + beta_1 * X)\n",
    "    sample_std_error = np.sqrt( np.sum(error_terms ** 2) / (n - 2) )\n",
    "\n",
    "    sample_std_pred = sample_std_error * np.sqrt( 1 + 1 / n * (1 + ((x0 - mean_X) ** 2 / (mean_X2 - mean_X ** 2))) )\n",
    "\n",
    "    y_pred = beta_0 + beta_1 * x0\n",
    "    t_crit = t.ppf((1 + confidence) / 2, df=n - 2)\n",
    "    margin_error = t_crit * sample_std_pred\n",
    "    pi_left, pi_right = (y_pred - margin_error, y_pred + margin_error)\n",
    "    latex_code = f\"\"\"\n",
    "        De eerste stap is om de puntschatting voor $Y$ te bepalen aan de hand van de regressielijn $Y = {pretty_print(beta_0)}{beta_1:+.4f} \\\\cdot X$ door $X = {x0}$ in te vullen.\n",
    "        Dit geeft ons een puntschatting van $y_0 = {pretty_print(beta_0)} {beta_1:+.4f} \\\\cdot {x0} \\\\approx {pretty_print(y_pred)}$.\n",
    "        Daarnaast kunnen we de standaardafwijking $\\\\sigma$ van de storingsterm $\\\\varepsilon$ schatten:\n",
    "        \\\\begin{{align*}}\n",
    "            s_{{\\\\varepsilon}} &= \\\\sqrt{{ \\\\frac{{n}}{{n-2}} \\\\cdot \\\\left( \\\\overline{{y^2}} - a \\\\cdot \\\\overline{{y}} - b \\\\cdot \\\\overline{{xy}} \\\\right) }} \\\\\\\\ \n",
    "                               &= \\\\sqrt{{ \\\\frac{{{n}}}{{{n-2}}} \\\\cdot \\\\left( {pretty_print(mean_Y2)} - {pretty_print(beta_0)} \\\\cdot {pretty_print(mean_Y)} - {pretty_print(beta_1)} \\\\cdot {pretty_print(mean_XY)} \\\\right) }} \\\\\\\\ \n",
    "                               &\\\\approx {pretty_print(sample_std_error)}. \n",
    "        \\\\end{{align*}}\n",
    "\n",
    "        Vervolgens kunnen we een puntschatting berekenen van de standaardafwijking van $Y$ voor gegeven $X = x_0$:\n",
    "        \\\\begin{{align*}}\n",
    "            s_{{f}} &= s_{{\\\\varepsilon}} \\\\cdot \\\\sqrt{{ 1 + \\\\frac{{1}}{{n}} \\\\cdot \\\\left( 1 + \\\\frac{{(x_0 - \\\\overline{{x}})^2}}{{\\\\overline{{x^2}} - \\\\overline{{x}}^2}} \\\\right) }} \\\\\\\\\n",
    "                    &= {pretty_print(sample_std_error)} \\\\cdot \\\\sqrt{{ 1 + \\\\frac{{1}}{{{n}}} \\\\cdot \\\\left( 1 + \\\\frac{{({x0} - {pretty_print(mean_X)})^2}}{{{pretty_print(mean_X2)} - {pretty_print(mean_X)}^2}} \\\\right) }} \\\\\\\\\n",
    "                    &\\\\approx {pretty_print(sample_std_pred)}.         \n",
    "        \\\\end{{align*}}\n",
    "\n",
    "        Omdat we de standaardafwijkingen geschat hebben en de storingstermen normaal verdeeld zijn, moeten we werken met de $t$-verdeling met $df = n - 2 = {n-2}$ vrijheidsgraden.\n",
    "        De $t$-waarde die hoort bij een betrouwbaarheidsniveau $\\\\alpha = {1-confidence}$ is gelijk aan\n",
    "        \\\\[\n",
    "            t = \\\\invt(\\\\text{{opp}} = 1 - \\\\alpha / 2; \\\\text{{df}} = n - 2) = \\\\invt(\\\\text{{opp}} = {1-alpha/2}; \\\\text{{df}} = {n-2}) \\\\approx {pretty_print(t_crit)}.\n",
    "        \\\\]\n",
    "        Het \\\\SI{{{confidence_percentage}}}{{\\\\percent}}-betrouwbaarheidsinterval voor de gemiddelde $Y$ voor gegeven $X = x_0$ kan dus worden beschreven door\n",
    "        \\\\begin{{align*}}\n",
    "            &[y_0 - t \\\\cdot s_{{f}}; y_0 - t \\\\cdot s_{{f}}] \\\\\\\\ \n",
    "            &= [{pretty_print(y_pred)} - {pretty_print(t_crit)} \\\\cdot {pretty_print(sample_std_pred)}; {pretty_print(y_pred)} + {pretty_print(t_crit)} \\\\cdot {pretty_print(sample_std_pred)}] \\\\\\\\ \n",
    "            &\\\\approx [{pretty_print(y_pred - margin_error)}; {pretty_print(y_pred + margin_error)}]. \n",
    "        \\\\end{{align*}}\n",
    "        \n",
    "        Met \\\\SI{{{confidence_percentage}}}{{\\\\percent}} betrouwbaarheid ligt een toekomstige uitkomst van $Y$ voor gegeven $X = {x0}$ tussen ${pretty_print(pi_left)}$ en ${pretty_print(pi_right)}$.\n",
    "    \"\"\"\n",
    "\n",
    "    return latex_code, y_pred, (pi_left, pi_right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af920de3-f8f9-4b77-a4bb-4cc2b048df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_midpoint_lines_and_quadrants(mean_X, mean_Y):\n",
    "    left, right = plt.xlim()\n",
    "    bottom, top = plt.ylim()\n",
    "\n",
    "    plt.axvline(mean_X, linestyle=\"--\", color=secondary_plot_color)\n",
    "    plt.axhline(mean_Y, linestyle=\"--\", color=secondary_plot_color)\n",
    "\n",
    "    p, q = 0.2, 0.8\n",
    "    quadrant_labels = [\n",
    "        (p * mean_X + (1 - p) * right, q * mean_Y + (1 - q) * top, \"> 0\", \"> 0\"),\n",
    "        (p * mean_X + (1 - p) * left, q * mean_Y + (1 - q) * top, \"< 0\", \"> 0\"),\n",
    "        (p * mean_X + (1 - p) * left, q * mean_Y + (1 - q) * bottom, \"< 0\", \"< 0\"),\n",
    "        (p * mean_X + (1 - p) * right, q * mean_Y + (1 - q) * bottom, \"> 0\", \"< 0\"),\n",
    "    ]\n",
    "    for x, y, dx, dy in quadrant_labels:\n",
    "        plt.text(x, y, f\"$x_i - \\\\overline{{x}} {dx}$\\n$y_i - \\\\overline{{y}} {dy}$\", ha=\"center\", va=\"center\")\n",
    "\n",
    "def fit_regression_and_plot_line(X, Y):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, Y)\n",
    "    x_vals = np.linspace(np.min(X), np.max(X), 200).reshape(-1, 1)\n",
    "    y_hat = model.predict(x_vals)\n",
    "\n",
    "    m, b = model.coef_[0], model.intercept_\n",
    "    label = f\"Regressielijn: $Y = {pretty_print(b)}{m:+.4f}X$\"\n",
    "    plt.plot(x_vals, y_hat, color=critical_color, label=label)\n",
    "\n",
    "    return model, x_vals.ravel(), y_hat\n",
    "\n",
    "def plot_residuals(X, Y, model):\n",
    "    for i, (xi, yi) in enumerate(zip(X[:, 0], Y)):\n",
    "        y_pred = model.predict([[xi]])[0]\n",
    "        label = \"Afstanden: $e_i = y_i - (a + b \\\\cdot x_i)$\" if i == 0 else None\n",
    "        plt.plot([xi, xi], [yi, y_pred], linestyle=\"--\", color=primary_plot_color, alpha=0.6, label=label)\n",
    "    \n",
    "def plot_y0(x_0, model):\n",
    "    left, right = plt.xlim()\n",
    "    bottom, top = plt.ylim()\n",
    "    y_0 = model.predict([[x_0]])[0]\n",
    "\n",
    "    plt.plot([x_0, x_0], [bottom, y_0], linestyle=\"--\", color=primary_plot_color)\n",
    "    plt.plot([left, x_0], [y_0, y_0], linestyle=\"--\", color=primary_plot_color,\n",
    "             label=f\"Puntschatting voor $Y \\\\mid X = {x_0}$: ${pretty_print(y_0)}$\")\n",
    "\n",
    "def plot_intervals(X, Y, x_vals, y_hat, model, x_0, plot_prediction_interval, plot_confidence_interval):\n",
    "    n = len(X)\n",
    "    x_mean = np.mean(X)\n",
    "    Sxx = np.sum((X - x_mean) ** 2)\n",
    "    residuals = Y - model.predict(X)\n",
    "    s_squared = np.sum(residuals ** 2) / (n - 2)\n",
    "    s = np.sqrt(s_squared)\n",
    "    t_val = t.ppf(0.975, df=n - 2)\n",
    "\n",
    "    se_mean = s * np.sqrt(1/n + (x_vals - x_mean)**2 / Sxx)\n",
    "    se_pred = s * np.sqrt(1 + 1/n + (x_vals - x_mean)**2 / Sxx)\n",
    "\n",
    "    ci_upper, ci_lower = y_hat + t_val * se_mean, y_hat - t_val * se_mean\n",
    "    pi_upper, pi_lower = y_hat + t_val * se_pred, y_hat - t_val * se_pred\n",
    "\n",
    "    if plot_prediction_interval:\n",
    "        plt.fill_between(x_vals, pi_lower, pi_upper, color=critical_color, alpha=0.2,\n",
    "                         label='Voorspellingsinterval (voor $Y \\\\mid X$)')\n",
    "        if x_0:\n",
    "            y_0 = model.predict([[x_0]])[0]\n",
    "            se_pred_0 = s * np.sqrt(1 + 1/n + (x_0 - x_mean)**2 / Sxx)\n",
    "            lower, upper = y_0 - t_val * se_pred_0, y_0 + t_val * se_pred_0\n",
    "            plt.plot([x_0, x_0], [lower, upper], color=critical_color, linestyle=\"--\", alpha=0.3,\n",
    "                     label=f'Voorspellingsinterval (voor $Y \\\\mid X={x_0}$): [{pretty_print(lower)}; {pretty_print(upper)}]')\n",
    "\n",
    "    if plot_confidence_interval:\n",
    "        plt.fill_between(x_vals, ci_lower, ci_upper, color=acceptable_color, alpha=0.3,\n",
    "                         label='Betrouwbaarheidsinterval (voor $E[Y \\\\mid X]$)')\n",
    "        if x_0:\n",
    "            y_0 = model.predict([[x_0]])[0]\n",
    "            se_mean_0 = s * np.sqrt(1/n + (x_0 - x_mean)**2 / Sxx)\n",
    "            lower, upper = y_0 - t_val * se_mean_0, y_0 + t_val * se_mean_0\n",
    "            plt.plot([x_0, x_0], [lower, upper], color=acceptable_color, linestyle=\"--\", alpha=0.3,\n",
    "                     label=f'Betrouwbaarheidsinterval (voor $E[Y \\\\mid X={x_0}$): [{pretty_print(lower)}; {pretty_print(upper)}]')\n",
    "            \n",
    "\n",
    "def plot_linear_regression(\n",
    "        X, Y, labels, filename, x_0=None,\n",
    "        plot_midpoint_lines=False, plot_least_squares=False, plot_regression_line=False, \n",
    "        plot_point_estimate=False,\n",
    "        plot_prediction_interval=False, plot_confidence_interval=False\n",
    "):\n",
    "    # Convert lists to numpy arrays\n",
    "    X = np.array(X).reshape(-1, 1)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    mean_X, mean_Y = np.mean(X), np.mean(Y)\n",
    "\n",
    "    # Create scatter plot\n",
    "    plt.scatter(X, Y, color=primary_plot_color)\n",
    "    plt.title(f'Spreidingsdiagram: {labels[\"X\"]} vs. {labels[\"Y\"]}')\n",
    "    \n",
    "    # Label axes and add title\n",
    "    plt.xlabel(labels[\"X\"])\n",
    "    plt.ylabel(labels[\"Y\"])\n",
    "\n",
    "    if plot_midpoint_lines:\n",
    "        add_midpoint_lines_and_quadrants(mean_X, mean_Y)\n",
    "              \n",
    "    if plot_regression_line:\n",
    "        model, x_vals, y_hat = fit_regression_and_plot_line(X, Y)\n",
    "    \n",
    "        if plot_least_squares:\n",
    "            plot_residuals(X, Y, model)\n",
    "\n",
    "        if x_0 and plot_point_estimate:\n",
    "            plot_y0(x_0, model)\n",
    "    \n",
    "        if plot_prediction_interval or plot_confidence_interval:\n",
    "            plot_intervals(X, Y, x_vals, y_hat, model, x_0, plot_prediction_interval, plot_confidence_interval)\n",
    "\n",
    "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), ncol=1)\n",
    "\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(filename, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e916c7db-d9a9-4f84-a638-8c51bcd3789c",
   "metadata": {},
   "source": [
    "### Voorbeeld gebruik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a992cc1a-e5a4-46fd-8c1a-ef4ad689dcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        \\begin{center}\n",
      "            \\begin{tabular}{c|cccccccccc}\n",
      "                \\toprule\n",
      "                    \\textbf{Slaaptijd (in uren)} & $7.4$ & $8.1$ & $8.3$ & $7.8$ & $7.9$ & $8.0$ & $7.7$ & $8.2$ & $7.6$ & $8.0$ \\\\\n",
      "                    \\textbf{Hersteltijd na zware inspanning (in uren)} & $8.3$ & $8.7$ & $8.9$ & $8.2$ & $8.5$ & $8.4$ & $8.8$ & $8.6$ & $8.3$ & $8.5$ \\\\\n",
      "                \\bottomrule\n",
      "            \\end{tabular}\n",
      "        \\end{center}\n",
      "    \n",
      "\n",
      "        \\begin{center}\n",
      "            \\begin{tabular}{ccccc}\n",
      "                \\toprule\n",
      "                    $x$ & $y$ & $xy$ & $x^2$ & $y^2$ \\\\\n",
      "                \\midrule\n",
      "    \t\t$7.4$ & $8.3$ & $61.42$ & $54.76$ & $68.89$ \\\\\n",
      "\t\t$8.1$ & $8.7$ & $70.47$ & $65.61$ & $75.69$ \\\\\n",
      "\t\t$8.3$ & $8.9$ & $73.87$ & $68.89$ & $79.21$ \\\\\n",
      "\t\t$7.8$ & $8.2$ & $63.96$ & $60.84$ & $67.24$ \\\\\n",
      "\t\t$7.9$ & $8.5$ & $67.15$ & $62.41$ & $72.25$ \\\\\n",
      "\t\t$8$ & $8.4$ & $67.2$ & $64$ & $70.56$ \\\\\n",
      "\t\t$7.7$ & $8.8$ & $67.76$ & $59.29$ & $77.44$ \\\\\n",
      "\t\t$8.2$ & $8.6$ & $70.52$ & $67.24$ & $73.96$ \\\\\n",
      "\t\t$7.6$ & $8.3$ & $63.08$ & $57.76$ & $68.89$ \\\\\n",
      "\t\t$8$ & $8.5$ & $68$ & $64$ & $72.25$ \\\\\n",
      "\n",
      "                \\midrule\n",
      "                    $\\overline{x} = 7.9$ & $\\overline{y} = 8.52$ & $\\overline{xy} = 67.343$ & $\\overline{x^2} = 62.48 & $\\overline{y^2} = 72.638$ \\\\\n",
      "                \\bottomrule\n",
      "            \\end{tabular}\n",
      "        \\end{center}\n",
      "    \n",
      "\n",
      "        \\begin{align*}\n",
      "            b &= \\frac{\\overline{xy} - \\overline{x} \\cdot \\overline{y}}{\\overline{x^2} - (\\overline{x})^2} \\\\\n",
      "              &= \\frac{67.343 - 7.9 \\cdot 8.52}{62.48 - (7.9)^2} \\\\\n",
      "              &= \\frac{0.035}{0.07} \\approx 0.5 \\\\\n",
      "            a &= \\overline{y} - b \\cdot \\overline{x} \\\\\n",
      "              &= 8.52 - 0.5 \\cdot 7.9 \\\\\n",
      "              &\\approx 4.57.\n",
      "        \\end{align*}\n",
      "\n",
      "        De formule van de regressielijn behorende bij deze steekproef is dus gelijk aan $Y = 4.57+0.5000X$.\n",
      "    \n",
      "Voorspelde waarde voor $Y$ bij $X = 6.75$ is gelijk aan 7.945000000000057\n",
      "\n",
      "        \\begin{align*}\n",
      "            r(x,y)  &= \\frac{ \\overline{x \\cdot y} - \\overline{x} \\cdot \\overline{y} }{ \\sqrt{ (\\overline{x}^2 - \\overline{x^2}) \\cdot (\\overline{y}^2 - \\overline{y^2}) } }\\\\\n",
      "                    &= \\frac{ 67.343 - 7.9 \\cdot 8.52 }{ \\sqrt{ (7.9^2 - 62.48) \\cdot (8.52^2 - 72.638) } } \\\\\n",
      "                    &= \\frac{0.035}{0.0577} \\\\\n",
      "                    &\\approx 0.6063.\n",
      "        \\end{align*}\n",
      "    \n",
      "[ 1.   8.  10.   4.   5.   6.5  3.   9.   2.   6.5] [ 2.5  8.  10.   1.   5.5  4.   9.   7.   2.5  5.5]\n",
      "\n",
      "        De eerste stap bij het berekenen van Spearman's correlatieco\\\"effici\\\"ent is het bepalen van de rankings van de uitkomsten voor $X$ en $Y$:\n",
      "        \\begin{center}\n",
      "            \\begin{tabular}{ccccccccccc}\n",
      "                \\toprule\n",
      "                    {\\bfseries Rangnummers $X$-waarden} & $1.0$ & $8.0$ & $10.0$ & $4.0$ & $5.0$ & $6.5$ & $3.0$ & $9.0$ & $2.0$ & $6.5$ \\\\\n",
      "                    {\\bfseries Rangnummers $Y$-waarden} & $2.5$ & $8.0$ & $10.0$ & $1.0$ & $5.5$ & $4.0$ & $9.0$ & $7.0$ & $2.5$ & $5.5$ \\\\\n",
      "                \\midrule\n",
      "                    {\\bfseries Verschillen $d_i$} & $-1.5$ & $0.0$ & $0.0$ & $3.0$ & $-0.5$ & $2.5$ & $-6.0$ & $2.0$ & $-0.5$ & $1.0$ \\\\\n",
      "                    {\\bfseries Kwadratische verschillen $d_i^2$} & $2.25$ & $0.0$ & $0.0$ & $9.0$ & $0.25$ & $6.25$ & $36.0$ & $4.0$ & $0.25$ & $1.0$ \\\\\n",
      "                \\bottomrule\n",
      "            \\end{tabular}\n",
      "        \\end{center}\n",
      "\n",
      "        De som van de kwadratische rangnummerverschillen is gelijk aan $\\sum_i d_i^2 = 59.0$.\n",
      "        Aangezien de steekproefgrootte gelijk is aan $n = 10$, is de rangcorrelatieco\\\"effici\\\"ent van Spearman gelijk aan\n",
      "        \\begin{align*}\n",
      "            r_s &= 1 - \\frac{ 6 \\cdot \\sum_i d_i^2 }{ n^3 - n }  \\\\\n",
      "                &= 1 - \\frac{ 6 \\cdot 59.0 }{ 10^3 - 10 }  \\\\\n",
      "                &\\approx 0.6424.\n",
      "        \\end{align*}\n",
      "    \n",
      "\n",
      "        De eerste stap is om de puntschatting voor $Y$ te bepalen aan de hand van de regressielijn $Y = 4.57+0.5000X$ door $X = 6.75$ in te vullen.\n",
      "        Dit geeft ons een puntschatting van $y_0 = 4.57 +0.5000 \\cdot 6.75 \\approx 7.945$.\n",
      "        Daarnaast kunnen we de standaardafwijking $\\sigma$ van de storingsterm $\\varepsilon$ schatten:\n",
      "        \\begin{align*}\n",
      "            s_{\\varepsilon} &= \\sqrt{ \\frac{n}{n-2} \\cdot \\left( \\overline{y^2} - a \\cdot \\overline{y} - b \\cdot \\overline{xy} \\right) } \\\\ \n",
      "                               &= \\sqrt{ \\frac{10}{8} \\cdot \\left( 72.638 - 4.57 \\cdot 8.52 - 0.5 \\cdot 67.343 \\right) } \\\\ \n",
      "                               &\\approx 0.194.\n",
      "        \\end{align*}\n",
      "\n",
      "        Vervolgens kunnen we een puntschatting berekenen van de standaardafwijking van de verwachtingswaarde van $Y$ voor gegeven $X = x_0$:\n",
      "        \\begin{align*}\n",
      "        s_{\\mu}  &= s_{\\varepsilon} \\cdot \\sqrt{ \\frac{1}{n} \\cdot \\left( 1 + \\frac{(x_0 - \\overline{x})^2}{\\overline{x^2} - \\overline{x}^2} \\right) } \\\\\n",
      "                    &= 0.19397164741270848 \\cdot \\sqrt{ \\frac{1}{10} \\cdot \\left( 1 + \\frac{(6.75 - 7.9)^2}{62.48 - 7.9^2} \\right) } \\\\\n",
      "                    &\\approx 0.2736.   \n",
      "        \\end{align*}\n",
      "\n",
      "        Omdat we de standaardafwijkingen geschat hebben en de storingstermen normaal verdeeld zijn, moeten we werken met de $t$-verdeling met $df = n - 2 = 8$ vrijheidsgraden.\n",
      "        De $t$-waarde die hoort bij een betrouwbaarheidsniveau $\\alpha = 0.09999999999999998$ is gelijk aan\n",
      "        \\[\n",
      "            t = \\invt(\\text{opp} = 1 - \\alpha / 2; \\text{df} = n - 2) = \\invt(\\text{opp} = 0.95; \\text{df} = 8) \\approx 1.8595.\n",
      "        \\]\n",
      "        Het $90\\%$-betrouwbaarheidsinterval voor de gemiddelde $Y$ voor gegeven $X = x_0$ kan dus worden beschreven door\n",
      "        \\begin{align*}\n",
      "            &[y_0 - t \\cdot s_{\\mu}; y_0 - t \\cdot s_{\\mu}] \\\\\n",
      "            &= [7.945 - 1.8595 \\cdot 0.2736; 7.945 + 1.8595 \\cdot 0.2736] \\\\\n",
      "            &\\approx [7.4363; 8.4537].\n",
      "        \\end{align*}\n",
      "        \n",
      "        Met \\SI{90}{\\percent} betrouwbaarheid ligt het gemiddelde van $Y$ voor gegeven $X = 6.75$ tussen $7.4363$ en $8.4537$.       \n",
      "    \n",
      "\n",
      "        De eerste stap is om de puntschatting voor $Y$ te bepalen aan de hand van de regressielijn $Y = 4.57+0.5000 \\cdot X$ door $X = 6.75$ in te vullen.\n",
      "        Dit geeft ons een puntschatting van $y_0 = 4.57 +0.5000 \\cdot 6.75 \\approx 7.945$.\n",
      "        Daarnaast kunnen we de standaardafwijking $\\sigma$ van de storingsterm $\\varepsilon$ schatten:\n",
      "        \\begin{align*}\n",
      "            s_{\\varepsilon} &= \\sqrt{ \\frac{n}{n-2} \\cdot \\left( \\overline{y^2} - a \\cdot \\overline{y} - b \\cdot \\overline{xy} \\right) } \\\\ \n",
      "                               &= \\sqrt{ \\frac{10}{8} \\cdot \\left( 72.638 - 4.57 \\cdot 8.52 - 0.5 \\cdot 67.343 \\right) } \\\\ \n",
      "                               &\\approx 0.194. \n",
      "        \\end{align*}\n",
      "\n",
      "        Vervolgens kunnen we een puntschatting berekenen van de standaardafwijking van $Y$ voor gegeven $X = x_0$:\n",
      "        \\begin{align*}\n",
      "            s_{f} &= s_{\\varepsilon} \\cdot \\sqrt{ 1 + \\frac{1}{n} \\cdot \\left( 1 + \\frac{(x_0 - \\overline{x})^2}{\\overline{x^2} - \\overline{x}^2} \\right) } \\\\\n",
      "                    &= 0.194 \\cdot \\sqrt{ 1 + \\frac{1}{10} \\cdot \\left( 1 + \\frac{(6.75 - 7.9)^2}{62.48 - 7.9^2} \\right) } \\\\\n",
      "                    &\\approx 0.3354.         \n",
      "        \\end{align*}\n",
      "\n",
      "        Omdat we de standaardafwijkingen geschat hebben en de storingstermen normaal verdeeld zijn, moeten we werken met de $t$-verdeling met $df = n - 2 = 8$ vrijheidsgraden.\n",
      "        De $t$-waarde die hoort bij een betrouwbaarheidsniveau $\\alpha = 0.09999999999999998$ is gelijk aan\n",
      "        \\[\n",
      "            t = \\invt(\\text{opp} = 1 - \\alpha / 2; \\text{df} = n - 2) = \\invt(\\text{opp} = 0.95; \\text{df} = 8) \\approx 1.8595.\n",
      "        \\]\n",
      "        Het \\SI{90}{\\percent}-betrouwbaarheidsinterval voor de gemiddelde $Y$ voor gegeven $X = x_0$ kan dus worden beschreven door\n",
      "        \\begin{align*}\n",
      "            &[y_0 - t \\cdot s_{f}; y_0 - t \\cdot s_{f}] \\\\ \n",
      "            &= [7.945 - 1.8595 \\cdot 0.3354; 7.945 + 1.8595 \\cdot 0.3354] \\\\ \n",
      "            &\\approx [7.3214; 8.5686]. \n",
      "        \\end{align*}\n",
      "        \n",
      "        Met \\SI{90}{\\percent} betrouwbaarheid ligt een toekomstige uitkomst van $Y$ voor gegeven $X = 6.75$ tussen $7.3214$ en $8.5686$.\n",
      "    \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)  # Zet de seed\n",
    "X = [4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0]\n",
    "            # + np.random.normal(loc=0, scale=40, size=len(Y))# oefeningstijd (min)\n",
    "Y = [66, 61, 63, 62, 65, 64, 57, 59, 60]\n",
    "\n",
    "X = [7.4, 8.1, 8.3, 7.8, 7.9, 8.0, 7.7, 8.2, 7.6, 8.0]  # F-16\n",
    "Y = [8.3, 8.7, 8.9, 8.2, 8.5, 8.4, 8.8, 8.6, 8.3, 8.5]  # F-35\n",
    "\n",
    "X_pred = 6.75\n",
    "labels = {\n",
    "    \"X\": \"Slaaptijd (in uren)\",\n",
    "    \"Y\": \"Hersteltijd na zware inspanning (in uren)\"\n",
    "}\n",
    "\n",
    "# Generate LaTeX table for the question itself (horizontal)\n",
    "latex_table = generate_latex_table(X, Y, labels)\n",
    "print(latex_table)\n",
    "\n",
    "# Plot X and Y in a scatter plot\n",
    "plot_linear_regression(X, Y, labels, x_0 = X_pred, \\\n",
    "                           plot_least_squares=False, plot_regression_line=False, \\\n",
    "                           plot_point_estimate=False, plot_prediction_interval=False,\\\n",
    "                           filename=FIGURE_PATH + \"20250725_q4_scatterplot.png\")\n",
    "\n",
    "# Generate LaTeX table for computing the regression line and the correlation coefficient\n",
    "regression_table = generate_latex_table_regression(X, Y)\n",
    "print(regression_table)\n",
    "\n",
    "regression_coefficients, a, b = regression_coefficients_latex(X, Y)\n",
    "print(regression_coefficients)\n",
    "\n",
    "Y_pred = a + b * X_pred\n",
    "print(f\"Voorspelde waarde voor $Y$ bij $X = {X_pred}$ is gelijk aan {Y_pred}\")\n",
    "\n",
    "pearson = pearson_correlation_latex(X, Y)\n",
    "print(pearson)\n",
    "\n",
    "spearman = spearman_correlation_latex(X, Y)\n",
    "print(spearman)\n",
    "\n",
    "# Confidence interval for the mean given x0\n",
    "x0 = 6.75\n",
    "alpha = 0.1\n",
    "\n",
    "confidence_interval, y_pred, ci = regression_confidence_interval(X, Y, a, b, x0, confidence=1-alpha)\n",
    "print(confidence_interval)\n",
    "\n",
    "prediction_interval, y_pred, pi = regression_prediction_interval(X, Y, a, b, x0, confidence=1-alpha)\n",
    "print(prediction_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bcc640-cef7-4920-9f4c-f8bca7ed3edf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee86d8-d6a9-4113-a430-a30035625420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
