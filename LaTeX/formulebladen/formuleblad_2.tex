\section*{Statistiek deel 2:}

\subsection*{Betrouwbaarheidsintervallen voor het gemiddelde $\mu$}
    \subsubsection*{Geval 1: $\sigma$ bekend}
        \textbf{\boldmath$100\cdot(1-\alpha)\%$-betrouwbaarheidsinterval (BI) voor \boldmath$\mu$:}
        \[
            z_{\alpha/2} = \text{InvNorm}(\text{opp}=1-\alpha/2; \mu=0; \sigma=1)
        \]
        \[
            [\overline{x} - z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{n}}; \overline{x} + z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{n}}]
        \]

        \textbf{Minimale steekproefomvang voor \boldmath$100\cdot(1-\alpha)\%$-BI als \boldmath$\mu$ maximaal \boldmath$\pm a$ mag afwijken:}
        \[
            n \ge \left( \frac{z_{\alpha/2} \cdot \sigma}{a} \right)^2
        \]

    \subsubsection*{Geval 2: $\sigma$ NIET bekend}
        \textbf{\boldmath$100\cdot(1-\alpha)\%$-betrouwbaarheidsinterval (BI) voor \boldmath$\mu$:}
        \[
            t = \invt(\text{opp}=1-\alpha/2; \text{df}=n-1)
        \]
        \[
            [\overline{x} - t \cdot \frac{s}{\sqrt{n}}; \overline{x} + t \cdot \frac{s}{\sqrt{n}}]
        \]

        \textbf{Minimale steekproefomvang voor $100\cdot(1-\alpha)\%$-BI als $\mu$ maximaal \boldmath$\pm a$ mag afwijken:}
        \[
            \text{GR tabel (voor verschillende $n$):} \quad \frac{s}{\sqrt{n}} \cdot \text{tcdf}(\text{opp}=1-\alpha/2; \text{df}=n-1) \le a
        \]
    
    {\itshape NB: zodra $n \ge 30$, vallen de normale en de $t$-verdeling nagenoeg samen. Je mag dan de schatting $s$ gebruiken als $\sigma$, zelfs als $\sigma$ zelf niet bekend is.}

\subsection*{Betrouwbaarheidsintervallen voor de binomiale succeskans $p$}
    \textbf{Betrouwbaarheidsinterval voor \boldmath$p$ (Clopper-Pearson):}
    Gegeven $n$ Bernoulli-experimenten, waarvan $k$ successen.
    \begin{enumerate}
        \item Bereken de succeskans $p_1$ zodat geldt $P(X \le k) = \binomcdf(n; p; k) = \alpha/2$
        \item Bereken de succeskans $p_2$ zodat geldt $P(X \ge k) = 1 - \binompdf(n; p; k-1) = \alpha/2$
        \item De berekende waarden voor $p_1$ en $p_2$ zijn de grenzen van het Clopper-Pearson interval.
    \end{enumerate}

\subsection*{Hypothesetoetsen}
    \textbf{Stappenplan hypothesetoetsen}
    \begin{enumerate}
        \item Definieer de nulhypothese $H_0$ en de alternatieve hypothese $H_1$.
        \item Bepaal het significantieniveau $\alpha$ (kans op Type-I fout, onterecht $H_0$ verwerpen)
        \item Verzamel data voor de toetsingsgrootheid
        \item Bereken de toetsingsgrootheid
        \item Geef een conclusie (met behulp van het kritieke gebied / $p$-waarde) en vertaal deze terug naar de originele probleemcontext.
    \end{enumerate}

    \newpage
    \textbf{Drie typen hypothesetoetsen: linkszijdig, tweezijdig, rechtszijdig}
    \begin{center}
        \includegraphics[width=0.72\linewidth]{left_sided.png}
        \includegraphics[width=0.72\linewidth]{two_sided.png}
        \includegraphics[width=0.72\linewidth]{right_sided.png}
    \end{center}
    {\itshape \textbf{NB:} voor elke kansverdeling (normaal, t, $\chi^2$, $F$) kun je het kritieke gebied berekenen door met de GR solver een vergelijking met $\alpha$ (links- of rechtszijdig) of twee vergelijkingen met $\alpha/2$ (tweezijdig) op te lossen. De $p$-waarde (overschrijdingskans) bepaal je met de CDF-functie van de desbetreffende kansverdeling.}

    \newpage
    \textbf{Soorten toetsen}
    \begin{table}[H]
        \centering
        \renewcommand{\arraystretch}{1.5}
        \begin{tabular}{c|c|c}
            \toprule
                \textbf{Soort toets} & \textbf{Toetsingsgrootheid} & \textbf{Kansverdeling (onder $H_0$)} \\
            \midrule
                \multicolumn{3}{c}{\textbf{Toetsen voor het gemiddelde $\mu \leq \mu_0$ of $\mu = \mu_0$ of $\mu \geq \mu_0$}} \\ 
            \midrule
                $z$-toets ($\sigma$ bekend)    & $\overline{X}$ & $N(\mu_0; \frac{\sigma}{\sqrt{n}})$ \\
                $t$-toets ($\sigma$ onbekend)  & $T = \frac{\overline{X} - \mu_0}{\frac{s}{\sqrt{n}}}$ & $t(\text{df}=n-1)$ \\
            \midrule
                \multicolumn{3}{c}{\textbf{Chikwadraattoetsen ($\chi^2$)}} \\
            \midrule
                Onafhankelijkheid & $X^2 = \sum_{i,j} \frac{(O_{ij} - E_{ij})^2}{E_{ij}}$ & $\chi^2(\text{df}=\text{(\#rijen-1)} \cdot \text{(\#kolommen-1)})$ \\
                Aanpassing (goodness-of-fit) & $X^2 = \sum_{i} \frac{(O_{i} - E_{i})^2}{E_{i}}$ & $\chi^2(\text{df}=\text{(\#categorie\"en-1)})$ \\
            \midrule
                \multicolumn{3}{c}{\textbf{Verschiltoetsen (op basis van twee populaties $A$ en $B$)}} \\
            \midrule
                $F$-toets: $\sigma_A^2 = \sigma_B^2$ & $F = \frac{S_1^2}{S_2^2}$ & $F(df1, df2)$ \\
                $z$-toets & $V =\overline{X_A} - \overline{X_B}$ & $N\left(\mu_A - \mu_B; \sqrt{\frac{\sigma_A^2}{n} + \frac{\sigma_B^2}{m}}\right)$ \\
                $t$-toets ($\sigma_A^2 = \sigma_B^2$) & $T = \frac{(\overline{x_A} - \overline{X_B}) - (\mu_A - \mu_B)}{\sqrt{\frac{S_P^2}{n} + \frac{S_P^2}{m}}}$ & $t(\text{df}=n+m-2)$ \\
                $t$-toets ($\sigma_A^2 \neq \sigma_B^2$) & $T = \frac{(\overline{X_A} - \overline{X_B}) - (\mu_A - \mu_B)}{\sqrt{\frac{S_A^2}{n} + \frac{S_B^2}{m}}}$ & $t(\text{df}=\min(n-1;m-1))$ \\
            \bottomrule
        \end{tabular}
    \end{table}

    \textbf{Beslisboom verschiltoetsen}

    \begin{tikzpicture}[node distance=4cm]

        % Nodes
        \node (sigmaKnown) [process] {$\sigma_A$ en $\sigma_B$ bekend?};
        \node (ztest) [process, below of=sigmaKnown, xshift=-4cm, align=center] {Voer $z$-toets uit met \\ $\displaystyle V = \overline{X_A} - \overline{X_B} \sim N\left(\mu_A - \mu_B; \sqrt{\frac{\sigma_A^2}{n} + \frac{\sigma_B^2}{m}}\right)$};
        \node (varEqual) [process, below of=sigmaKnown, xshift=4cm, align=center] {Voer $F$-toets uit \\ Wordt $H_0: \sigma_A^2 = \sigma_B^2$ geaccepteerd?};
        \node (pooledT) [process, below of=varEqual, xshift=-4cm, yshift=-1.5cm, align=center] {Voer $t$-toets ($\sigma_A^2 = \sigma_B^2$) uit \\ met ``pooled variance'' \\ $\displaystyle s_P^2 = \frac{(n-1)\cdot s_A^2 + (m-1) \cdot s_B^2}{n-1+m-1}$};
        \node (welchT) [process, below of=varEqual, xshift=2cm, yshift=-1.5cm, align=center] {Voer $t$-toets ($\sigma_A^2 \neq \sigma_B^2$) uit \\ $\displaystyle t = \frac{(\overline{x_A} - \overline{x_B}) - (\mu_A - \mu_B)}{\sqrt{\frac{s_A^2}{n} + \frac{s_B^2}{m}}}$}; % \\ ($\text{df}=\min(n-1; m-1)$)};

        % Arrows
        \draw [arrow] (sigmaKnown) -- node[above, sloped] {ja} (ztest);
        \draw [arrow] (sigmaKnown) -- node[above, sloped] {nee} (varEqual);
        \draw [arrow] (varEqual) -- node[above, sloped] {ja} (pooledT);
        \draw [arrow] (varEqual) -- node[above,sloped] {nee} (welchT);

    \end{tikzpicture}

\newpage

\subsection*{Correlatie en regressie}

\textbf{Correlatieco\"effici\"ent van Pearson:}
\[
    r = \frac{\overline{xy} - \overline{x} \cdot \overline{y}}{\sqrt{(\overline{x^2} - \overline{x}^2)\cdot(\overline{y^2} - \overline{y}^2)}}
\]

\textbf{Correlatieco\"effici\"ent van Spearman:}
\[
    r_s = 1 - \frac{6 \sum_i d_i^2}{n^3-n}
\]

\textbf{Co\"effici\"enten van de lineaire regressielijn $Y = a + b\cdot X$:}
\begin{align*}
    b &= \frac{\overline{xy} - \overline{x} \cdot \overline{y}}{\overline{x^2} - (\overline{x})^2} \\
    a &= \overline{y} - b \cdot \overline{x}
\end{align*}

\textbf{Schatting van de variantie van de storingsterm $\varepsilon$:}
\begin{align*}
    s_{\varepsilon} &= \frac{\sum e_i^2}{n - 2} = \frac{\sum \left(y_i - (a + b \cdot x_i)\right)^2}{n - 2}=  \sqrt{ \frac{n}{n-2} \cdot \left( \overline{y^2} - a \cdot \overline{y} - b \cdot \overline{xy} \right) } \\ 
\end{align*}

\textbf{\boldmath$100\cdot(1-\alpha)\%$-betrouwbaarheidsinterval voor de gemiddelde $Y$ bij gegeven $X = x_0$:}
\[
    t = \invt(\text{opp} = 1 - \alpha/2; \text{df} = n - 2)
\]
\[
    s_\mu = s_{\varepsilon} \cdot \sqrt{ \frac{1}{n} \cdot \left( 1 + \frac{(x_0 - \overline{x})^2}{\overline{x^2} - \overline{x}^2} \right) }
\]
\[
    [a+b\cdot x_0 - t \cdot s_\mu; a+b\cdot x_0 + t \cdot s_\mu]
\]

\textbf{\boldmath$100\cdot(1-\alpha)\%$-betrouwbaarheidsinterval voor $Y$ bij gegeven $X = x_0$:}
\[
    t = \invt(\text{opp} = 1 - \alpha/2; \text{df} = n - 2)
\]
\[
    s_f = s_{\varepsilon} \cdot \sqrt{ 1 + \frac{1}{n} \cdot \left( 1 + \frac{(x_0 - \overline{x})^2}{\overline{x^2} - \overline{x}^2} \right) }
\]
\[
    [a+b\cdot x_0 - t \cdot s_f; a+b\cdot x_0 + t \cdot s_f]
\]

% \textbf{Covariance:}
% \[
%     Cov(X, Y) = E[(X-E[X])\cdot(Y-E[Y])] = E[X\cdot Y] - E[X]E[Y]
% \]

% \textbf{Correlation coefficient:}
% \[
%     \rho(X, Y) = \frac{Cov(X,Y)}{\sqrt{Var(X) \cdot Var(Y)}}
% \]

% \textbf{Variance of error terms:}
% \[ \hat{\sigma}^2 = \frac{1}{n-2}\sum_{i=1}^{n} (y_{i} - \hat{y}_{i})^2 = \frac{\sum_{i=1}^{n} y_{i}^2 - \hat{\beta}_{0}\cdot \sum_{i=1}^{n} y_{i} - \hat{\beta}_{1}\cdot \sum_{i=1}^{n} x_{i}y_{i}}{n-2}\]

% \textbf{Coefficients of regression line:}

% Given a sample of $n$ observations $(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)$, the regression line $\hat{y} = \hat{\beta}_0 + \hat{\beta}_{1}\cdot x$ satisfies:
% \begin{itemize}
%     \item $\hat{\beta}_{1} = \frac{\sum_{i=1}^{n}x_iy_i - n \cdot \overline{x} \cdot \overline{y}}{\sum_{i=1}^{n} x_{i}^2 - n \cdot \overline{x}^2}$
%     \item $\hat{\beta}_{0} = \overline{y} - \hat{\beta}_{1} \cdot \overline{x}$
% \end{itemize}

% \textbf{Sample correlation coefficient:}
% \[ r(X, Y) = \frac{Cov(X, Y)}{\sqrt{s_{X}^2\cdot s_{Y}^2}} = \frac{\sum_{i=1}^{n}(x_{i}-\overline{x})\cdot(y_{i} - \overline{y})}{\sqrt{\sum_{i=1}^{n}(x_{i}-\overline{x})^2 \cdot \sum_{i=1}^{n}(y_{i}-\overline{y})^2}} = \frac{\sum_{i=1}^{n}x_{i}y_{i} - n \cdot \overline{x}\cdot \overline{y}}{\sqrt{\left(\sum_{i=1}^{n}x_{i}^2-n\cdot \overline{x}^2\right) \cdot \left(\sum_{i=1}^{n}y_{i}^2-n\cdot \overline{y}^2\right)}}\]

% \textbf{Likelihood function:}
% \[ L(x_1, x_2, \ldots, x_n; \theta) = f(x_1; \theta)\cdot f(x_2; \theta)\cdot\ldots\cdot f(x_n; \theta)\]

% \textbf{Minimum sample size with given accuracy $E$:}
% \[ n \ge \left(\frac{z_{\frac{\alpha}{2}} \cdot \sigma}{E}\right)^2\]

% \textbf{Minimum sample size for bounding type II error $\beta$}
% \[ n \ge \frac{(z_{\frac{\alpha}{2}}+z_{\beta})^2 \cdot \sigma^2}{\delta^2}\]

% \textbf{Veelgebruikte functies op de grafische rekenmachine}
% \begin{table}[H]
%     \centering
%     \begin{tabular}{c|c|c}
%         \toprule
%             \textbf{Vraag}                     & \textbf{TI-84 Plus}           & \textbf{Casio} \\
%         \midrule
%             \multicolumn{3}{c}{\textbf{Continue kansverdeling (willekeurig)}} \\ 
%         \midrule
%             $z_{p}$                      & invNorm$(\text{opp}=1-p; \mu=0; \sigma=1)$      & InvNormCD$(\text{opp}=1-p; \sigma=1; \mu=0)$\\
%             $t_{p}$                      & invNorm$(\text{opp}=1-p; \mu=0; \sigma=1)$      & InvNormCD$(\text{opp}=1-p; \sigma=1; \mu=0)$\\
%         \midrule    
%             \multicolumn{3}{c}{\textbf{$X \sim \text{Binomiaal}(n, p)$}} \\ 
%         \midrule
%             $P(X = k)$                              & binompdf$(n,p,k)$             & BinomialPD$(k, n, p)$ \\
%             $P(X \le k)$                            & binomcdf$(n,p,k)$             & BinomialCD$(k, n, p)$ \\
%         \midrule    
%             \multicolumn{3}{c}{\textbf{$X \sim N(\mu, \sigma)$}} \\
%         \midrule 
%             $P(a \le X \le b)$                      & normalcdf$(a,b,\mu,\sigma)$   & NormalCD$(a, b, \sigma, \mu)$ \\
%             % Grenswaarde $g$ zodat $P(X \le g)=p$?   & invNorm$(p,\mu,\sigma)$       & InvNormCD$(\text{tail=left}, p, \sigma, \mu)$ \\
%         \midrule 
%             \multicolumn{3}{c}{\textbf{$X \sim \text{Poisson}(\lambda)$}} \\  
%         \midrule
%             $P(X = k)$                              & poissonpdf$(\lambda, k)$      & PoissonPD$(k, \lambda)$ \\
%             $P(X \le k)$                            & poissoncdf$(\lambda, k)$      & PoissonCD$(k, \lambda)$ \\
%         \bottomrule
%     \end{tabular}
% \end{table}

\end{document}
